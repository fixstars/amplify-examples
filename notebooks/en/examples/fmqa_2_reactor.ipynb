{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Box Optimization of Operating Condition in a Chemical Reactor\n",
    "\n",
    "As a practical example of black-box optimization (we may call it FMQA), we will work on optimization using numerical simulations of nonlinear physical phenomena as the objective function.\n",
    "\n",
    "In this tutorial, the goal is to optimize the operating condition of a plant reactor to maximize production. The chemical reaction and transport phenomena of reactants and products in the reactor are predicted by numerical simulations using the finite difference method. Based on the predicted results, optimization is performed to maximize the amount of material production in the reactor.\n",
    "\n",
    "Note that the simulation code used in this example is implemented in `Python` and can be called directly from the `FMQA` class which is introduced later. However, even if this is not the case (e.g. if the machines for FMQA execution and simulation execution are different or the objective function is based on experimental measurements), this example code can be used almost as is.\n",
    "\n",
    "For an introduction to the black-box optimization and FMQA, see \"[Black-Box Optimization Exploration of Model Superconducting Materials](https://amplify.fixstars.com/en/demo/fmqa_0_algebra)\". For another advanced application case using FMQA, see \"[Black-Box Optimization of Airfoil Geometry by Fluid Flow Simulation](https://amplify.fixstars.com/en/demo/fmqa_3_aerofoil)\".\n",
    "\n",
    "This notebook contains the following sections.\n",
    "\n",
    "- 1\\. [Problem setting](#1)\n",
    "  - 1.1\\. [Reactor model and optimization target](#1_1)\n",
    "  - 1.2\\. [Description of the reactor simulator](#1_2)\n",
    "  - 1.3\\. [Implementation of the reactor simulator](#1_3)\n",
    "  - 1.4\\. [Simulation examples and definition of the objective function](#1_4)\n",
    "- 2\\. [FMQA program implementation](#2)\n",
    "  - 2.1\\. [Random seed initialization](#2_1)\n",
    "  - 2.2\\. [Configuration of Amplify client](#2_2)\n",
    "  - 2.3\\. [Implementing FM with PyTorch](#2_3)\n",
    "  - 2.4\\. [Construction of initial training data](#2_4)\n",
    "  - 2.5\\. [Execution class for FMQA cycle](#2_5)\n",
    "- 3\\. [Search for optimal operating conditions](#3)\n",
    "  - 3.1\\. [FMQA execution example](#3_1)\n",
    "  - 3.2\\. [Transition of objective function values during the optimization process](#3_2)\n",
    "  - 3.3\\. [Example output from this FMQA sample program](#3_3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1\\. Problem setting\n",
    "\n",
    "This section describes the problem definition in this example code and the simulation of the reactor used as the objective function. However, black-box optimization treats the objective function as a black box, so it is unnecessary to understand this simulation code.\n",
    "\n",
    "<a id=\"1_1\"></a>\n",
    "### 1.1\\. Reactor model and optimization target\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../figures/fmqa_2_reactor/fmqa_2_schematic_en.png\" title=\"Schematic of the reactor\">\n",
    "</div>\n",
    "\n",
    "As shown in the figure above, we consider a chemical reactor controlled solely by the initial concentration distribution of the reactive substance A. In this reactor, the chemical reaction $A \\rightarrow B$ occurs at a reaction rate based on the concentration distributions of A and B, producing the product B.\n",
    "\n",
    "The goal of the present optimization is to maximize the total amount of B produced within a given production time $\\Delta t_{prod}$ by appropriately determining the initial concentration distribution of A to improve productivity (think of it as a problem of minimizing the negative value of the total amount)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_2\"></a>\n",
    "### 1.2\\. Description of the reactor simulator\n",
    "\n",
    "This time, instead of considering reactors in actual three-dimensional (3D) space, we will focus on one-dimensional (1D) reactors for the sake of simulation cost. Such a reactor can be seen as, for example,\n",
    "\n",
    "- A chemical reactor with a long and thin vessel, or\n",
    "- A chemical reactor homogeneous in the y- and z-directions\n",
    "\n",
    "Note that the essence of the present exercise, i.e., optimization for the reactor operating conditions, is independent of the dimension considered.\n",
    "\n",
    "The chemical reaction and transport phenomena in the reactor are described by the following nonlinear partial differential equations, where $C_A$ denotes the concentration of substance A (reactant) and $C_B$ denotes the concentration of substance B (product).\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_A}{\\partial t} = \\alpha \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial C_A}{\\partial x}\\right) - \\omega\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_B}{\\partial t} = \\alpha \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial C_B}{\\partial x}\\right) + \\omega\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\omega = R_r C_A (1-C_A) \\exp{(-C_B)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_B = O \\text{ at } t=0 \\:\\:\\text{(initially, there is no B)}\n",
    "$$  \n",
    "\n",
    "Given an initial concentration distribution of A, $C_{A,0}$, the total production of B within the production time $\\Delta t_{prod}$ corresponds to the spatial integral of $C_B$ in the reactor at $\\Delta t_{prod}$ from the beginning of the simulation and can be obtained with the simulation class `Reactor` described next."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_3\"></a>\n",
    "### 1.3\\. Implementation of the reactor simulator\n",
    "\n",
    "The `integrate` function of the `Reactor` class simulates reactions in the chemical reactor. This simulator solves the above equations using the finite difference method, similar to commercially available physical simulation software using finite element or finite volume methods.\n",
    "\n",
    "Here, the `integrate` function takes an initial concentration distribution of A, $C_{A,0}$, as an argument and returns the total amount of B produced (the spatial integral of the concentration distribution of B) obtained after the simulation is run for the physical time of $\\Delta t_{prod}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# A class to solve the transport equations (partial differential equations) for the concentration of a given reactive substance (A->B) by finite difference methods.\n",
    "\n",
    "\n",
    "class Reactor:\n",
    "    def __init__(self, nfolds=5, alpha=1.0, dt_prod=1e-3, rr=1e4):\n",
    "        self.nfolds = nfolds  # Parameters that determine the spatial resolution of the simulation domain\n",
    "        self.alpha = alpha  # Molecular diffusion coefficient\n",
    "        self.dt_prod = dt_prod  # Predetermined production time\n",
    "        self.rr = rr  # Coefficients related to the reaction rate\n",
    "\n",
    "    # Function to compute the second-order derivative of the distribution f by second-order central differencing (assuming periodic boundary conditions)\n",
    "\n",
    "    def __dfdx2(self, f, dfdx2):\n",
    "        dfdx2[0] = (f[1] - 2 * f[0] + f[self.nx - 1]) / self.dx / self.dx\n",
    "        dfdx2[self.nx - 1] = (\n",
    "            (f[0] - 2 * f[self.nx - 1] + f[self.nx - 2]) / self.dx / self.dx\n",
    "        )\n",
    "        dfdx2[1 : self.nx - 1] = (\n",
    "            np.array([f[i + 1] - 2 * f[i] + f[i - 1] for i in range(1, self.nx - 1)])\n",
    "            / self.dx\n",
    "            / self.dx\n",
    "        )\n",
    "        return dfdx2\n",
    "\n",
    "    # Determine the initial conditions\n",
    "\n",
    "    def __init_field(self, x):\n",
    "        self.nx = self.nfolds * len(\n",
    "            x\n",
    "        )  # Number of mesh points used in the spatial discretization\n",
    "        self.dx = 1.0 / (self.nx - 1)  # Mesh point spacing\n",
    "        self.concn_A = np.zeros(self.nx)  # Concentration distribution of A\n",
    "        self.concn_B = np.zeros(self.nx)  # Concentration distribution of B\n",
    "        self.x_cord = np.array(\n",
    "            [i / self.nx - 0.5 for i in range(self.nx)]\n",
    "        )  # Coordinate of discrete points\n",
    "        self.concn_A = np.array(\n",
    "            [float(x[i]) for i in range(len(x)) for j in range(self.nfolds)]\n",
    "        )  # Generate the initial field for A\n",
    "\n",
    "    # Function to evolve the transport equation in time by dt_prod physical time according to the initial distribution init_A of A and return the total amount of B produced\n",
    "\n",
    "    def integrate(self, init_A, fig=False):\n",
    "        self.__init_field(init_A)\n",
    "        start = time.perf_counter()\n",
    "        omega = np.zeros(self.nx)\n",
    "        dfdx2 = np.zeros(self.nx)\n",
    "        dt = 0.25 * self.dx * self.dx / self.alpha  # Time step width in Eulerian method\n",
    "        lts = int(self.dt_prod / dt)\n",
    "        if fig:  # Plot of reaction progress\n",
    "            fig = plt.figure(figsize=(6, 4))\n",
    "            plt.tick_params(labelsize=16)\n",
    "            plt.xlabel(\"x\", fontsize=16)\n",
    "            plt.ylabel(\"Concentration\", fontsize=18)\n",
    "            plt.plot(\n",
    "                self.x_cord,\n",
    "                self.concn_A,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                color=[0.6, 0.6, 0.6],\n",
    "                label=\"$C_{A,0}$\",\n",
    "            )\n",
    "        self.iter = 0\n",
    "        while self.iter * dt < self.dt_prod:\n",
    "            if fig and any(\n",
    "                [\n",
    "                    self.iter == i\n",
    "                    for i in [0, int(0.1 * lts), int(0.2 * lts), int(0.4 * lts)]\n",
    "                ]\n",
    "            ):  # Plot of reaction progress\n",
    "                plt.plot(\n",
    "                    self.x_cord, self.concn_B, linestyle=\"-\", linewidth=2, color=\"r\"\n",
    "                )\n",
    "            omega = (\n",
    "                self.rr * np.exp(-self.concn_B) * self.concn_A * (1.0 - self.concn_A)\n",
    "            )  # Reaction rate\n",
    "            self.concn_A = (\n",
    "                self.concn_A\n",
    "                + (self.alpha * self.__dfdx2(self.concn_A, dfdx2) - omega) * dt\n",
    "            )  # Time advancement for the concentration of A\n",
    "            self.concn_B = (\n",
    "                self.concn_B\n",
    "                + (self.alpha * self.__dfdx2(self.concn_B, dfdx2) + omega) * dt\n",
    "            )  # Time advancement for the concentration of B\n",
    "            self.iter += 1\n",
    "        if fig:  # Plot of reaction progress\n",
    "            plt.plot(\n",
    "                self.x_cord,\n",
    "                self.concn_B,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=4,\n",
    "                color=\"r\",\n",
    "                label=\"$C_B$\",\n",
    "            )\n",
    "            plt.legend(fontsize=16)\n",
    "        self.cpu_time = time.perf_counter() - start  # Measure the computation time\n",
    "        return (\n",
    "            np.sum(self.concn_B) * self.dx\n",
    "        )  # Simplified spatial integration of the concentration of B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_4\"></a>\n",
    "### 1.4\\. Simulation examples and definition of the objective function\n",
    "\n",
    "Now, let's execute the reaction simulator using the `integrate` function of the `Reactor` class. The function returns the total amount of B produced during the production time, given an initial concentration distribution $C_{A,0}$ of A (which is set by a random number for now). The first argument of the `integrate` function is a 1D binary array representing the distribution of $C_{A,0}$ in 1D space (i.e., $C_{A,0}$ takes either 0 or 1 in each coordinate). The second argument is an optional output flag for the result image (`False` by default).\n",
    "\n",
    "Upon execution, the following result image is obtained according to $C_{A,0}$, which is determined based on a random number.\n",
    "\n",
    "![Simulation_result_0](../figures/fmqa_2_reactor/fmqa_2_sim_res_0.png)\n",
    "![Simulation_result_1](../figures/fmqa_2_reactor/fmqa_2_sim_res_1.png)\n",
    "![Simulation_result_2](../figures/fmqa_2_reactor/fmqa_2_sim_res_2.png)\n",
    "\n",
    "The resulting image above shows the initial concentration distribution of A $C_{A,0}$ (gray) and the concentration distribution of B at each time $C_B$ (red). The concentration distribution of B is shown at time $t=0$ (initial concentration distribution, bottom red line at $C_{B,0}=0$), $t=0.1 \\Delta t_{prod}$ (second red line from the bottom), $t= 0.2 \\Delta t_{prod}$ (third red line from the bottom), $t=0.4 \\Delta t_{prod}$ (fourth red line from the bottom), $t = \\Delta t_{prod}$ (production end time, top bold red line). In this optimization exercise, the goal is to maximize the integral value of the bold red line in the reactor.\n",
    "\n",
    "At time 0, $C_B=C_{B,0}=0$ in the whole region, but with time, the chemical reaction proceeds, and B is produced ($C_B$ increases). The final concentration distribution of B at the end of the production time is shown by the bold red line. The time evolution of reactant A is not shown, but it is assumed that $C_{A}$ gradually decreases over time due to chemical reactions and molecular diffusion.\n",
    "\n",
    "Since the random seed value is not fixed in the example code below, $C_{A,0}$ changes with each run, and the total production of B changes accordingly. Can you imagine what the initial concentration distribution $C_{A,0}$ of A that maximizes the total production of B would look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1D binary array representing C_{A,0} by random numbers\n",
    "# Discretize 1D space into 100 finite regions to represent the initial distribution of C_A\n",
    "# Random seed is not fixed, so the contents of c_a0 change with each run\n",
    "c_a0 = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Reaction simulation is performed by the `integrate`` function of the Reactor class (option to output result image)\n",
    "amount_B = Reactor().integrate(c_a0, fig=True)\n",
    "\n",
    "# Output the total amount of B produced\n",
    "print(f\"Total amount of B: {amount_B:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the reactor domain is discretized with 100 *finite volume*, as in the above code, there are $2^{100} \\sim 10^{30}$ possible values that the initial concentration distribution $C_{A,0}$ vector of A can take. Also, from the reaction rate equation $\\omega$ in [section 1.2](#1_2), in order to maximize the production of B in time, it is not simply a matter of filling the entire reactor with A (i.e. $C_{A,0} = $`[1, 1, 1,.... , 1]`), but it is necessary to devise a way to fill it with as much A as possible, while appropriately arranging the local region where $C_A=0$. For such a system,\n",
    "\n",
    "- The search space is large, and a full search is unrealistic due to the time cost of the simulation,\n",
    "- The objective function is an unknown function (described by a nonlinear partial differential equation) and is a black box.\n",
    "\n",
    "\n",
    "Therefore, the use of FMQA is considered as effective.\n",
    "\n",
    "Although the material cost depends on the amount of A initially present in the reactor, we assume that the cost of reactant A is small compared to the price of product B and that the effect of the material cost on the overall cost is negligible.\n",
    "\n",
    "As an objective function, we define a function `my_obj_func` that returns the negative value of the total production of B obtained from the simulation. This is because FMQA optimizes to minimize the value of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function (returns the negative value of the total amount of product B produced)\n",
    "def my_obj_func(init_A, fig=False):\n",
    "    my_reactor = Reactor()\n",
    "    minus_total = -my_reactor.integrate(init_A, fig)\n",
    "    if fig:\n",
    "        # (Optional) Displays objective function value, number of integrations in integrate(), and CPU time required for the simulation\n",
    "        print(f\"{minus_total=:.2e}, {my_reactor.iter=}, {my_reactor.cpu_time=:.1e}s\")\n",
    "    return minus_total\n",
    "\n",
    "\n",
    "# Example 1: objective function value when a certain binary vector c_a0 (defined in the cell above) is fed\n",
    "amount_B = my_obj_func(c_a0)\n",
    "print(f\"{amount_B=:.2f}\")\n",
    "\n",
    "# Example 2: Objective function value when a certain binary vector c_a0 (defined in the cell above) is fed (log and image as well)\n",
    "amount_B = my_obj_func(c_a0, fig=True)\n",
    "print(f\"{amount_B=:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2\\. FMQA program implementation\n",
    "\n",
    "This section describes the program implementation of FMQA, which is identical to the implementation in \"[Black-Box Optimization with Quantum Annealing and Ising Machines](https://amplify.fixstars.com/en/demo/fmqa_0_algebra)\", so please refer to that for details.\n",
    "\n",
    "<a id=\"2_1\"></a>\n",
    "### 2.1．Random seed initialization\n",
    "\n",
    "We define a function `seed_everything()` to initialize random seed values to ensure that the machine learning results do not change with each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_2\"></a>\n",
    "### 2.2．Configuration of Amplify client\n",
    "\n",
    "Here, we create an Amplify client and set the necessary parameters. In the following, we set the timeout for a single search by the Ising machine to 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import FixstarsClient\n",
    "from datetime import timedelta\n",
    "\n",
    "client = FixstarsClient()\n",
    "client.parameters.timeout = timedelta(milliseconds=1000)  # timeout is 1000 ms\n",
    "# client.token = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # If you use Amplify in a local environment, enter the Amplify API token."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_3\"></a>\n",
    "### 2.3．Implementing FM with PyTorch\n",
    "\n",
    "In this example code, FM is implemented with PyTorch. In the `TorchFM` class, we define the acquisition function $g(x)$ as a machine learning model. Each term in $g(x)$ corresponds directly to `out_lin`, `out_1`, `out_2`, and `out_inter` in the `TorchFM` class, as in the following equation.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  g(\\boldsymbol{x} | \\boldsymbol{w}, \\boldsymbol{v}) &= \\underset{\\color{red}{\\mathtt{out\\_lin}}}{\\underline{ w_0 + \\sum_{i=1}^n w_i x_i} } + \\underset{\\color{red}{\\mathtt{out\\_inter}}}{\\underline{\\frac{1}{2}\\left(\\underset{\\color{red}{\\mathtt{out\\_1}}}{\\underline{ \\sum_{f=1}^k\\left(\\sum_{i=1}^n v_{i f} x_i\\right)^2 }} - \\underset{\\color{red}{\\mathtt{out\\_2}}}{\\underline{ \\sum_{f=1}^k\\sum_{i=1}^n v_{i f}^2 x_i^2 }} \\right) }}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TorchFM(nn.Module):\n",
    "    def __init__(self, d: int, k: int):\n",
    "        super().__init__()\n",
    "        self.V = nn.Parameter(torch.randn(d, k), requires_grad=True)\n",
    "        self.lin = nn.Linear(\n",
    "            d, 1\n",
    "        )  # The first and second terms on the right-hand side are fully connected network\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x, self.V).pow(2).sum(1, keepdim=True)\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(1, keepdim=True)\n",
    "        out_inter = 0.5 * (out_1 - out_2)\n",
    "        out_lin = self.lin(x)\n",
    "        out = out_inter + out_lin\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a function `train()` is defined to train the FM based on the training data sets. As in general machine learning methods, this function divides the data sets into training data and validation data, then optimizes the FM parameters using the training data, and validates the model during training using the validation data. The `train()` function returns the model with the highest prediction accuracy for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Type\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def train(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model_class: Type[nn.Module],\n",
    "    model_params: dict[str, int | float],\n",
    "    batch_size=1024,\n",
    "    epochs=3000,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    "    opt_params={\"lr\": 1},\n",
    "    lr_sche_class=None,\n",
    "    lr_sche_params=None,\n",
    "):\n",
    "    X_tensor, y_tensor = (\n",
    "        torch.from_numpy(X).float(),\n",
    "        torch.from_numpy(y).float(),\n",
    "    )\n",
    "    indices = np.array(range(X.shape[0]))\n",
    "    indices_train, indices_valid = train_test_split(\n",
    "        indices, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_set = TensorDataset(X_tensor[indices_train], y_tensor[indices_train])\n",
    "    valid_set = TensorDataset(X_tensor[indices_valid], y_tensor[indices_valid])\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "        \"valid\": DataLoader(valid_set, batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    optimizer = optimizer_class(model.parameters(), **opt_params)\n",
    "    scheduler = None\n",
    "    if lr_sche_class is not None:\n",
    "        scheduler = lr_sche_class(optimizer, **lr_sche_params)\n",
    "    best_score = 1e18\n",
    "    for _ in range(epochs):\n",
    "        losses = {\"train\": 0.0, \"valid\": 0.0}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            for batch_x, batch_y in loaders[phase]:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch_x).T[0]\n",
    "                loss = criterion(out, batch_y)\n",
    "                losses[phase] += loss.item() * batch_x.size(0)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "            losses[phase] /= len(loaders[phase].dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            if best_score > losses[\"valid\"]:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_score = losses[\"valid\"]\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_4\"></a>\n",
    "### 2.4．Construction of initial training data\n",
    "\n",
    "The `gen_training_data` function evaluates the objective function $f(\\boldsymbol{x})$ against the input value $\\boldsymbol{x}$ to produce $N_0$​​ input-output pairs (initial training data). The input value $\\boldsymbol{x}$ can be determined in a variety of ways, such as by using a random number or a value suitable for machine learning based on prior knowledge. You can also build up the training data from the results of previous experiments or simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_data(D: int, N0: int, true_func):\n",
    "    assert N0 < 2**D\n",
    "    # N0 input values are obtained using random numbers\n",
    "    X = np.random.randint(0, 2, size=(N0, D))\n",
    "    # Remove duplicate input values and add new input values using random numbers\n",
    "    X = np.unique(X, axis=0)\n",
    "    while X.shape[0] != N0:\n",
    "        X = np.vstack((X, np.random.randint(0, 2, size=(N0 - X.shape[0], D))))\n",
    "        X = np.unique(X, axis=0)\n",
    "    y = np.zeros(N0)\n",
    "    # Obtain output values corresponding to N0 input values by evaluating the objective function, true_func\n",
    "    for i in range(N0):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Generating {i}-th training data set.\")\n",
    "        y[i] = true_func(X[i])\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_5\"></a>\n",
    "### 2.5．Execution class for FMQA cycle\n",
    "\n",
    "`FMQA.cycle()` executes an FMQA cycle that is performed for $N−N_0$​​ times using the pre-prepared initial training data. `FMQA.step()` is a function that executes only one FMQA cycle, and is called $N−N_0$​​ times by `FMQA.cycle()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import VariableGenerator, solve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "class FMQA:\n",
    "    def __init__(self, D: int, N: int, N0: int, k: int, true_func, client) -> None:\n",
    "        assert N0 < N\n",
    "        self.D = D\n",
    "        self.N = N\n",
    "        self.N0 = N0\n",
    "        self.k = k\n",
    "        self.true_func = true_func\n",
    "        self.client = client\n",
    "        self.y = None\n",
    "\n",
    "    # A member function that repeatedly performs (N-N0)x FMQA based on the training data with adding new training data\n",
    "    def cycle(self, X, y, log=False) -> np.ndarray:\n",
    "        print(f\"Starting FMQA cycles...\")\n",
    "        pred_x = X[0]\n",
    "        pred_y = 1e18\n",
    "        for i in range(self.N - self.N0):\n",
    "            print(f\"FMQA Cycle #{i} \", end=\"\")\n",
    "            try:\n",
    "                x_hat = self.step(X, y)\n",
    "            except RuntimeError:\n",
    "                sys.exit(f\"Unknown error, i = {i}\")\n",
    "            # If an input value identical to the found x_hat already exists in the current training data set, a neighboring value is used as a new x_hat.\n",
    "            is_identical = True\n",
    "            while is_identical:\n",
    "                is_identical = False\n",
    "                for j in range(i + self.N0):\n",
    "                    if np.all(x_hat == X[j, :]):\n",
    "                        change_id = np.random.randint(0, self.D, 1)\n",
    "                        x_hat[change_id.item()] = 1 - x_hat[change_id.item()]\n",
    "                        if log:\n",
    "                            print(f\"{i=}, Identical x is found, {x_hat=}\")\n",
    "                        is_identical = True\n",
    "                        break\n",
    "            # Evaluate objective function f() with x_hat\n",
    "            y_hat = self.true_func(x_hat)\n",
    "            # Add an input-output pair [x_hat, y_hat] to the training data set\n",
    "            X = np.vstack((X, x_hat))\n",
    "            y = np.append(y, y_hat)\n",
    "            # Copy the input-output pair to [pred_x, pred_y] when the evaluated value of the objective function updates the minimum value\n",
    "            if pred_y > y_hat:\n",
    "                pred_y = y_hat\n",
    "                pred_x = x_hat\n",
    "                print(f\"variable updated, {pred_y=}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "            # Exit the \"for\" statement if all inputs have been fully explored\n",
    "            if len(y) >= 2**self.D:\n",
    "                print(f\"Fully searched at {i=}. Terminating FMQA cycles.\")\n",
    "                break\n",
    "        self.y = y\n",
    "        return pred_x\n",
    "\n",
    "    # Member function to perform one FMQA cycle\n",
    "    def step(self, X, y) -> np.ndarray:\n",
    "        # Train FM\n",
    "        model = train(\n",
    "            X,\n",
    "            y,\n",
    "            model_class=TorchFM,\n",
    "            model_params={\"d\": self.D, \"k\": self.k},\n",
    "            batch_size=8,\n",
    "            epochs=2000,\n",
    "            criterion=nn.MSELoss(),\n",
    "            optimizer_class=torch.optim.AdamW,\n",
    "            opt_params={\"lr\": 1},\n",
    "        )\n",
    "        # Extract FM parameters from the trained FM model\n",
    "        v, w, w0 = list(model.parameters())\n",
    "        v = v.detach().numpy()\n",
    "        w = w.detach().numpy()[0]\n",
    "        w0 = w0.detach().numpy()[0]\n",
    "        # Solve a QUBO problem using a quantum annealing or Ising machine\n",
    "        gen = VariableGenerator()  # Declare a variable generator\n",
    "        q = gen.array(\"Binary\", self.D)  # Generate binary decision variables\n",
    "        model = self.__FM_as_QUBO(q, w0, w, v)  # Define FM as a QUBO equation\n",
    "        result = solve(model, self.client)  # Pass the objective function to Amplify\n",
    "        if len(result.solutions) == 0:\n",
    "            raise RuntimeError(\"No solution was found.\")\n",
    "        q_values = q.evaluate(result.best.values)\n",
    "        return q_values\n",
    "\n",
    "    # A function that defines FM as a QUBO equation from FM parameters. As with the previously defined TorchFM class, the formula is written as per the acquisition function form of g(x).\n",
    "    def __FM_as_QUBO(self, x, w0, w, v):\n",
    "        lin = w0 + (x.T @ w)\n",
    "        out_1 = np.array([(x * v[:, i]).sum() ** 2 for i in range(self.k)]).sum()\n",
    "        # Note that x[j] = x[j]^2 since x[j] is a binary variable in the following equation.\n",
    "        out_2 = np.array([(x * v[:, i] * v[:, i]).sum() for i in range(self.k)]).sum()\n",
    "        return lin + (out_1 - out_2) / 2\n",
    "\n",
    "    # A function to plot the history of i-th objective function evaluations performed within the initial training data construction (blue) and during FMQA cycles (red).\n",
    "    def plot_history(self):\n",
    "        assert self.y is not None\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        plt.plot(\n",
    "            [i for i in range(self.N0)],\n",
    "            self.y[: self.N0],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            color=\"b\",\n",
    "        )  # Objective function evaluation values at the time of initial training data generation (random process)\n",
    "        plt.plot(\n",
    "            [i for i in range(self.N0, self.N)],\n",
    "            self.y[self.N0 :],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            color=\"r\",\n",
    "        )  # Objective function evaluation values during the FMQA cycles (FMQA cycle process)\n",
    "        plt.xlabel(\"i-th evaluation of f(x)\", fontsize=18)\n",
    "        plt.ylabel(\"f(x)\", fontsize=18)\n",
    "        plt.tick_params(labelsize=18)\n",
    "        return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3．Search for optimal operating conditions\n",
    "\n",
    "<a id=\"3_1\"></a>\n",
    "### 3.1\\. FMQA execution example\n",
    "\n",
    "Now, using the reactor simulator introduced in section [1.4](#1_4) as the objective function, we will perform optimization to maximize the total amount of B produced in a given time (minimize the negative value of the total amount) by the FMQA implemented in section [2](#2).\n",
    "\n",
    "The objective function is evaluated $N=30$ times, of which $N_0$=20 for initial data generation. Thus, in the example below, the FMQA cycle (machine learning, seeking the optimal solution in a QUBO manner, and the objective function evaluation) is performed $N-N_0=10$ times. With this setup, it takes approximately 1-5 minutes to complete the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random seed values\n",
    "seed_everything()\n",
    "\n",
    "D = 100  # Size of input values (problem size)\n",
    "N = 30  # Number of times the function can be evaluated\n",
    "N0 = 20  # Number of samples of initial training data\n",
    "k = 20  # Dimension of the vector in FM (hyperparameters)\n",
    "\n",
    "# Generate initial training data\n",
    "X, y = gen_training_data(D, N0, my_obj_func)\n",
    "\n",
    "# Instantiate FMQA class\n",
    "fmqa_reactor = FMQA(D, N, N0, k, my_obj_func, client)\n",
    "\n",
    "# Run FMQA cycle\n",
    "pred_x = fmqa_reactor.cycle(X, y, log=True)\n",
    "\n",
    "# Output optimization results\n",
    "print(\"pred x:\", pred_x)\n",
    "print(\"pred value:\", my_obj_func(pred_x, fig=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3_2\"></a>\n",
    "### 3.2\\. Transition of objective function values during the optimization process\n",
    "\n",
    "The following line displays the evolution of the objective function values during the optimization process (see the output example in \"[3.3\\. Example output from this FMQA sample program](#3_3)\").\n",
    "\n",
    "The initial $N_0$​ objective function values (blue line) are obtained from randomly generated input values during initial training data generation. The following red line shows the objective function values during the $N−N_0$​ FMQA optimization cycles.\n",
    "\n",
    "The blue and red lines show how the smallest objective function value is successively updated from the currently optimal input value (red line) obtained by the FMQA optimization cycle.\n",
    "\n",
    "In general, due to the principle of the heuristics algorithm employed in `FixstarsClient`, the solutions obtained are not perfectly reproducible, but when solved for the parameters in the above sample code, the resulting solution (initial concentration distribution of A) exceeds 0.8 for the total production of B. Compared to a random search (blue), this shows a substantial improvement in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fmqa_reactor.plot_history()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3_3\"></a>\n",
    "### 3.3\\. Example output from this FMQA sample program\n",
    "\n",
    "In general, due to the principle of the heuristics algorithm employed in `FixstarsClient`, the solutions obtained are not completely reproducible, but the following is a typical standard output and image output obtained when this sample code is executed. The values obtained may vary.\n",
    "\n",
    "- Without changing the conditions in \"[FMQA execution example](#3_1)\", the following standard output is sequentially output as the FMQA cycle progresses. The following figure is also output as a simulation result based on the optimized initial distribution of A.\n",
    "\n",
    "  ```shell\n",
    "  Generating 0-th training data set.\n",
    "  Generating 10-th training data set.\n",
    "  Starting FMQA cycles...\n",
    "  FMQA Cycle #0 variable updated, pred_y=-0.0\n",
    "  FMQA Cycle #1 variable updated, pred_y=-0.7341318540009673\n",
    "  FMQA Cycle #2 variable updated, pred_y=-0.7836727189544249\n",
    "  FMQA Cycle #3 variable updated, pred_y=-0.7862647410081264\n",
    "  FMQA Cycle #4 \n",
    "  FMQA Cycle #5 \n",
    "  FMQA Cycle #6 \n",
    "  FMQA Cycle #7 variable updated, pred_y=-0.8310535978823115\n",
    "  FMQA Cycle #8 \n",
    "  FMQA Cycle #9 \n",
    "  pred x: [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  2. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  3. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
    "  4. 1. 1. 1.]\n",
    "  minus_total=-8.31e-01, my_reactor.iter=997, my_reactor.cpu_time=3.7e-01s\n",
    "  pred value: -0.8310535978823115\n",
    "  ```\n",
    "\n",
    "  ![optimized_reaction](../figures/fmqa_2_reactor/fmqa_2_sim_res_opt.png)\n",
    "\n",
    "- The output image from `fmqa_reactor.plot_history()` described in \"[3.2\\. Transition of objective function values during optimization process](#3_2)\" is as follows.\n",
    "\n",
    "  ![history](../figures/fmqa_2_reactor/fmqa_2_history.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
