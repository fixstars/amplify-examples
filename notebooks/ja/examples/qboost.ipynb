{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBoost\n",
    "\n",
    "このノートでは QBoost と呼ばれるアニーリングマシンを用いた機械学習手法を紹介します。\n",
    "\n",
    "## 目次\n",
    "\n",
    "- QBoostとは\n",
    "- データセットの生成\n",
    "- データセットの分割\n",
    "- 弱分類器の多数決による分類\n",
    "- Amplify AEを用いた改良\n",
    " - ノイズとなる分類器を除去する手法による結果\n",
    " - ブースティングの思想を取り入れたQBoostによる結果\n",
    "- まとめ\n",
    "\n",
    "前提知識として、教師あり学習、教師なし学習、分類、学習、テスト、バリデーションなどの単語の意味を知っていることを仮定します。\n",
    "\n",
    "\n",
    "## QBoostとは\n",
    "\n",
    "QBoostは機械学習の手法の一つで、アンサンブル学習（Ensemble Learning）といわれる分野に分類されます。より具体的には、ブースティングの思想を取り入れたバギングを行なっています。\n",
    "\n",
    "アンサンブル学習は別々に学習させた分類器（Classifier）を組み合わせて推論させる学習方法のことで、独立に学習した分類器・回帰モデルの出力の多数決もしくは平均を取る手法（バギング）、過去に学習した分類器の出力を元に、学習済みの分類器の弱点を補うように新しい分類器を学習する手法（ブースティング）などがあります。\n",
    "\n",
    "理論的には、バギングを用いることで予測のブレ（分散、バリアンス）を軽減し、ブースティングにより予測のズレ（偏り、バイアス）を減少させることが期待されます。バイアスとバリアンスがともに小さいモデルが理想ですが、この二つは互いにトレードオフの関係にあることが知られています。\n",
    "\n",
    "アンサンブル手法の最も単純な実装は、各分類器の出力の多数決をとるバギングと呼ばれる手法です。しかし、単純に多数決を取るだけではいわゆる「良くない」分類器が紛れ込んでいた場合に、思ったように精度が上がらないなどの問題があります。QBoost はそのような問題の解決を試みる方法です。以下では、扱う問題の説明から始め、実際に Amplify を用いて単純な多数決よりも精度が向上することを確認します。\n",
    "\n",
    "## データセットの生成\n",
    "\n",
    "まずはQBoostを評価するためのデータセットを作成します。\n",
    "\n",
    "今回使用するデータセットは、`scikit-learn` に含まれている `iris_dataset` です。`iris_dataset`とは、計3種類のアヤメとそれに対応する4つの特徴量（花弁の長さ・幅、ガクの長さ・幅）が含まれたデータセットであり、この特徴量を用いてアヤメの分類を行うことが今回の目標です。つまり、教師あり学習による3クラス分類に取り組みます。このデータセットには150個分のアヤメのデータが含まれています。\n",
    "\n",
    "以下が各種類のアヤメの写真です（wikipediaから引用）。パッと見ただけではほとんど違いがわからないと思います。\n",
    "\n",
    "![](./figures/iris_pictures.png)\n",
    "\n",
    "次のように `iris_dataset` を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "data, label = np.array(iris_dataset[\"data\"]), np.array(iris_dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの分割\n",
    "\n",
    "次にデータセットを学習データとテストデータに分割します。ここでは適当に60%を学習データ、20%をテストデータ、残りの20%をバリデーションデータとしています。データセットの分割には`scikit-learn`の`train_test_split`関数を使用します。クラスごとのデータ数に偏りが少なくなるように分割できています。\n",
    "\n",
    "後ほど詳しく説明しますが、今回は、各クラスに対してそのクラスに属しているか否かを判別する2値分類器を用いて3クラス分類を行うため、それに適した形になるようにラベルを二次元配列で整形します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "num_classes = len(set(label))\n",
    "\n",
    "# データセットに含まれるラベルが2種類なら分類器は１クラス分あれば良い\n",
    "if num_classes == 2:\n",
    "    num_classes = 1\n",
    "\n",
    "# 全体の 20% をテストデータに分割する\n",
    "X_train, X_test, y_train_tmp, y_test_tmp = train_test_split(\n",
    "    data, label, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "# 残りの 25% (全体の20%) をバリデーションデータに分割する\n",
    "X_train, X_valid, y_train_tmp, y_valid_tmp = train_test_split(\n",
    "    X_train, y_train_tmp, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# 分類数xデータ数の二次元配列を作成しデータに対応した正解ラベルを表す\n",
    "# 一致していたら1, 不一致の場合 -1\n",
    "y_train = np.full(shape=(num_classes, len(X_train)), fill_value=-1)\n",
    "y_test = np.full(shape=(num_classes, len(X_test)), fill_value=-1)\n",
    "y_valid = np.full(shape=(num_classes, len(X_valid)), fill_value=-1)\n",
    "\n",
    "\n",
    "def update_label(y, tmp):\n",
    "    for i, label in enumerate(tmp):\n",
    "        y[label, i] = 1\n",
    "\n",
    "\n",
    "# 正解ラベルを配列に埋め込む\n",
    "update_label(y_train, y_train_tmp)\n",
    "update_label(y_test, y_test_tmp)\n",
    "update_label(y_valid, y_valid_tmp)\n",
    "\n",
    "# データ数を表示\n",
    "print(f\"train data: {len(X_train)}\")\n",
    "for cls in range(num_classes):\n",
    "    print(\"train\", f\"label {cls}:\", np.sum(y_train_tmp == cls))\n",
    "print(f\"test data: {len(X_test)}\")\n",
    "for cls in range(num_classes):\n",
    "    print(\"test\", f\"label {cls}:\", np.sum(y_test_tmp == cls))\n",
    "print(f\"validation data: {len(X_valid)}\")\n",
    "for cls in range(num_classes):\n",
    "    print(\"validation\", f\"label {cls}:\", np.sum(y_valid_tmp == cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの可視化\n",
    "from itertools import combinations\n",
    "\n",
    "# 各特徴量の名前\n",
    "feature_names = iris_dataset.feature_names\n",
    "\n",
    "\n",
    "def plot_features(X, Y, fig=None):\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # 二次元のグラフを作りたいので特徴量の組み合わせを作る\n",
    "    for i, (x, y) in enumerate(combinations(range(4), 2)):\n",
    "        # サブグラフ\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        # 各品種はマーカーの色や形を変える\n",
    "        for t, marker, c in zip(range(3), \">ox\", \"rgb\"):\n",
    "            plt.scatter(\n",
    "                X[Y == t, x],\n",
    "                X[Y == t, y],\n",
    "                marker=marker,\n",
    "                c=c,\n",
    "                label=feature_names[t],\n",
    "            )\n",
    "            plt.xlabel(feature_names[x])\n",
    "            plt.ylabel(feature_names[y])\n",
    "    plt.autoscale()\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "test_original = plot_features(X_test, y_test_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 弱分類器の作成\n",
    "\n",
    "次に、アンサンブル学習で使用する弱分類器を作成します。今回は弱分類器として、深さ1の決定木(Decision Tree)を各クラスごとに100個、合計で300個使用します。余談ですが、深さ1の決定木は決定株とも呼ばれます。\n",
    "\n",
    "決定木の内部実装に関しては今回の本質ではないため、scikit-learnパッケージを使用しますが、今回は各分類器 ごとに学習データの中から決められたサンプル数 (`num_samples=5`) だけ取り出して学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "# 乱数シードを固定\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 分類器を二次元リストで作成\n",
    "num_classifiers = 100\n",
    "num_samples = 5\n",
    "depth = 1\n",
    "classifiers = [\n",
    "    [DTC(splitter=\"random\", max_depth=depth) for _ in range(num_classes)]\n",
    "    for _ in range(num_classifiers)\n",
    "]\n",
    "\n",
    "# 決定木を学習\n",
    "all_indices = np.arange(X_train.shape[0])\n",
    "for classifier in classifiers:\n",
    "    for i in range(num_classes):\n",
    "        sample_indices = np.random.choice(all_indices, num_samples)\n",
    "        classifier[i].fit(X=X_train[sample_indices], y=y_train[i, sample_indices])\n",
    "\n",
    "print(f\"number of classifiers {num_classifiers * num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多数決による分類\n",
    "\n",
    "まずはアンサンブル学習を分類問題に適用する際の基本である、多数決による結果を計算します。全ての弱学習器の結果の最頻値を分類器全体の出力と解釈します。このように、独立に学習した弱分類器を用いたアンサンブル学習を一般にバギングと呼びます。特に、独立に学習した決定木をバギングによってアンサンブルする手法をランダムフォレストと呼びます。\n",
    "\n",
    "今回はラベルが±1をとる2値分類を扱っているため、実装上は分類器 $i$ の予測ラベルを $y_i\\in\\{-1, 1\\}$ として、$\\text{sign}\\left(\\sum_{i=1}^{\\#\\textit{classifiers}}y_i\\right)$ を計算することで多数決を実現しています。\n",
    "問題自体が非常に簡単な部類のため、この時点でもかなり良い精度が出ています。\n",
    "\n",
    "用意した分類器の精度は、以下のようにして確認します。\n",
    "1. ラベルiに対応する分類器のみを用いて、正しく分類できているか確かめる(i=0, 1, 2)\n",
    "2. 用意した分類器を全て使用し、正しく分類できているか確かめる\n",
    "\n",
    "2に関しては、データがラベルiである、と予測した分類器が最も多いラベルを分類器全体の出力とみなして正解率を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "results = {\n",
    "    \"多数決\": dict(),\n",
    "    \"QBoost(step 1)\": dict(),\n",
    "    \"QBoost(step 2)\": dict(),\n",
    "}  # 結果保存用\n",
    "\n",
    "# テストデータとバリデーションデータに対して推論\n",
    "test_predictions_of_classifiers = np.array(\n",
    "    [\n",
    "        [classifier[i].predict(X_test) for i in range(num_classes)]\n",
    "        for classifier in classifiers\n",
    "    ]\n",
    ")\n",
    "valid_predictions_of_classifiers = np.array(\n",
    "    [\n",
    "        [classifier[i].predict(X_valid) for i in range(num_classes)]\n",
    "        for classifier in classifiers\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 多数決\n",
    "for l in range(num_classes):\n",
    "    predictions_vote = np.sign(np.sum(test_predictions_of_classifiers[:, l, :], axis=0))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test[l], y_pred=predictions_vote)\n",
    "\n",
    "    # クラスごとの正解率を表示\n",
    "    print(f\"Majority vote of weak classifiers class {l}: {accuracy*100} %\")\n",
    "    results[\"多数決\"][f\"class {l}\"] = accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全てのラベルに対応する分類器の出力を統合した分類結果の正解率を取得\n",
    "if num_classes > 2:\n",
    "    tmp = np.sum(test_predictions_of_classifiers, axis=0)\n",
    "    m_vote = np.argmax(tmp, axis=0)\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test_tmp, y_pred=m_vote)\n",
    "    print(f\"Majority vote of weak classifiers: {accuracy*100} %\")\n",
    "    results[\"多数決\"][\"Total\"] = accuracy * 100\n",
    "    results[\"多数決\"][\"num_classifiers\"] = num_classes * num_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplify を用いた QBoost の実装\n",
    "\n",
    "このセクションでは、上記の単純な多数決の結果の改善を目指して、Amplify を用いた QBoost の実装について解説します。1段階目としてノイズとなる余計な分類器を除外する手法を紹介し、二段階目に弱分類器の修正を行う手法 (QBoost) を解説します。\n",
    "\n",
    "### 1段階目：最適な分類器の組み合わせを求める\n",
    "\n",
    "まず、QBoostの導入となる単純な手法を紹介します。\n",
    "この手法のアイデアは、全ての分類器の中から最も高い精度が得られる組み合わせを求めてそれを使用するというものです。つまり、ノイズとなる余計な分類器を除外します。そこで「各分類器に対して、それを使用するか/しないか」をバイナリ変数で表します。\n",
    "\n",
    "まずは2クラス分類に対する定式化を行います。\n",
    "\n",
    "2クラス分類において、いくつかの弱分類器を取り除いたあと残ったものの多数決によって分類を行うとき、その結果は\n",
    "\n",
    "$$ H(x) = {\\rm sign}\\left(\\sum_{i=1}^{C}s_i h_i(x)\\right)$$\n",
    "\n",
    "となります。ここで、$C$は分類器の数、$h_i(x) \\in \\{-1, 1\\}$は弱分類器、$s_i \\in \\{0, 1\\}$はバイナリ変数です。\n",
    "\n",
    "今回の目的を達成するために一番自然な目的関数は、誤分類の個数を数え、それを最小化すること、つまり\n",
    "$$\\left(1-\\textit{label}_x\\times{\\rm sign}\\left(\\sum_{i=1}^{C}s_i h_i(x_j)\\right)\\right)/2$$\n",
    "を最小化することです。\n",
    "しかし、これは符号関数が含まれ非凸なので最適化が難しいです。\n",
    "そこで、代わりにその上界である\n",
    "$$\\left(\\textit{label}_x\\times\\sum_{i=1}^{C}s_i h_i(x)-1\\right)^2$$\n",
    "を最小化することで、目的を達成しようと試みることにします。\n",
    "\n",
    "一方で、使用する弱学習器が多すぎる場合、過学習によりテストデータの正解率が低くなってしまうことがあります。\n",
    "それを防ぐため、使用する弱分類器の数$\\sum_{i=1}^Cs_i$をペナルティ項として上の式に重みをつけて足し合わせます。\n",
    "\n",
    "したがって、2クラス分類においては、バイナリ変数を最適化するために最小化すべき関数は以下のようになります。\n",
    "\n",
    "$$ s_{\\textit{min}} = \\mathop{\\rm arg~min}\\limits_{s} \\sum_{j=1}^{N_{\\textit{train}}}\\left(y_j\n",
    "\\sum_{i=1}^{C}s_i h_i(x_j)-1\\right)^2 + P\\sum_{i=1}^{C}s_i$$\n",
    "\n",
    "$N_{\\textit{train}}$は学習データの数、$y_j \\in \\{-1, 1\\}$はデータ$x_j$に対するラベル、$P$ は使用する弱分類器の数に対するペナルティ係数です。この値を大きく設定するほど、使用する弱学習器が少なくなります。\n",
    "\n",
    "次に、クラスごとに2値分類を行った結果を統合して多クラス分類を行うことを考えます。 \n",
    "今回の例では$3(\\textrm{クラス数})\\times100(\\textrm{クラスごとの分類器数})$、計300個の弱分類器を使用しているため、300個のバイナリ変数を定義し、\n",
    "以下の関数を最小化します。\n",
    "$$ s_{min} = \\mathop{\\rm arg~min}\\limits_{s} \\sum_{j=1}^{N_{train}}\\sum_{l=0}^{\\#labels-1}\\left(y_j\n",
    "\\sum_{i=1}^{C}s_{li} h_{li}(x_j)-1\\right)^2 + P\\sum_{l=0}^{\\#labels-1}\\sum_{i=1}^{C}s_{li}$$\n",
    "\n",
    "これは、2クラス分類で見たのと同様に、それぞれのラベルに対し、そのラベルの分類精度を向上させるような弱分類器の組み合わせを求めることを目的としています。\n",
    "\n",
    "このようにして使用する弱分類器を決定したあと、次のように新しい分類器$G(x)$を定義します。\n",
    "\n",
    "$$ G(x) = {\\rm arg~max}_l\\left\\{\\sum_{i=1}^{C}s_{li} h_{li} \\mid l=0,1,\\dots\\#\\textit{labels}-1\\right\\} $$\n",
    "\n",
    "(今回は、$\\#\\textit{labels}=3$に相当します。)\n",
    "$C$は分類器の数、$h_{li}(x) \\in \\{-1, 1\\}$は弱分類器、$s_{li} \\in \\{0, 1\\}$はバイナリ変数です。\n",
    "\n",
    "$ \\displaystyle\\sum_{i=1}^{C}s_{li} h_{li}(x) $ は、ラベル$l$に対応する分類器のなかで、データ$x$に対応するラベルが$l$であると予測した分類器の数の多さを表現しているため、この値が最も大きいラベルを予測として出力することで、多数決を達成することができます。\n",
    "\n",
    "参考文献：[Training a Binary Classifier with the\n",
    "Quantum Adiabatic Algorithm](https://arxiv.org/abs/0811.0416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、前処理として、学習データに対する各分類器の出力を求め、Amplify AEを用いた最適化のための変数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import BinarySymbolGenerator\n",
    "\n",
    "\n",
    "def preprocess(classifiers):\n",
    "    \"\"\"最適化に必要な変数の定義と学習データに対する分類器の出力を計算\"\"\"\n",
    "    # Prepare spins\n",
    "    gen = BinarySymbolGenerator()\n",
    "    spins = gen.array(shape=(num_classifiers, num_classes))\n",
    "\n",
    "    # Obtain predictions for train data\n",
    "    train_predictions_of_classfiers = np.array(\n",
    "        [\n",
    "            [classifier[i].predict(X_train) for i in range(num_classes)]\n",
    "            for classifier in classifiers\n",
    "        ]\n",
    "    )\n",
    "    return spins, train_predictions_of_classfiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、目的関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import sum_poly\n",
    "\n",
    "\n",
    "def createQUBO(spins, penalty, train_predictions_of_classifiers):\n",
    "    \"\"\"QUBOとして最適化する関数を定義\"\"\"\n",
    "    # 各データ、各クラスラベルに対応する分類器について、分類器の総和をとる。\n",
    "    tmp = (np.expand_dims(spins, -1) * train_predictions_of_classifiers).sum(0)\n",
    "    tmp = (y_train * tmp - 1) ** 2\n",
    "    f = tmp.sum()\n",
    "\n",
    "    f += penalty * spins.sum()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、最適化と結果の取り出しを行う関数を作成します。 \n",
    "最適化にはアニーリングマシン（Fixstars Amplify AE）が使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import Solver, decode_solution\n",
    "from amplify.client import FixstarsClient\n",
    "\n",
    "\n",
    "def solve(f, spins, solver=None):\n",
    "    \"\"\"Amplify AEを用いて最適化\"\"\"\n",
    "    if solver is None:\n",
    "        client = FixstarsClient()\n",
    "        client.parameters.timeout = 1000\n",
    "        solver = Solver(client)\n",
    "    # Solve QUBO formulation\n",
    "    result = solver.solve(f)\n",
    "    solution = decode_solution(spins, result[0].values)\n",
    "    # 最適化結果の取り出し\n",
    "    use_indices = [\n",
    "        np.where(solution[:, l] == 1)[0].tolist() for l in range(num_classes)\n",
    "    ]\n",
    "    return use_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、最適化の結果得られた分類器の正解率を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(use_indices, predictions_of_classifiers, y_true):\n",
    "    \"\"\"与えられたインデックスに対応する分類器による推論結果と正解率を計算\"\"\"\n",
    "    model_predictions = []\n",
    "    accuracy_each_class = []\n",
    "    ACCEPT = True\n",
    "    for i in range(num_classes):\n",
    "        if (\n",
    "            len(use_indices[i]) == 0\n",
    "        ):  # 全く使われないクラスの分類器がある場合、結果を採用しない\n",
    "            ACCEPT = False\n",
    "            break\n",
    "        model_predictions.append(\n",
    "            np.sum(predictions_of_classifiers[use_indices[i]][:, i, :], axis=0)\n",
    "        )\n",
    "        accuracy = metrics.accuracy_score(\n",
    "            y_true=y_true[i], y_pred=list(map(np.sign, model_predictions[i]))\n",
    "        )\n",
    "        accuracy_each_class.append(accuracy)\n",
    "    return np.array(model_predictions), np.array(accuracy_each_class), ACCEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを実行すると、上記の一連の操作が実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = (\n",
    "    len(X_train) / num_classes / num_classifiers\n",
    ")  # ペナルティ項の係数。今回は決め打ち\n",
    "\n",
    "# Obtain predictions for train data　and prepare spins\n",
    "spins, train_predictions_of_classifiers = preprocess(classifiers)\n",
    "# Create QUBO formulation\n",
    "f = createQUBO(spins, penalty, train_predictions_of_classifiers)\n",
    "use_indices = solve(f, spins)\n",
    "# バリデーションデータに対する正解率を計算\n",
    "valid_pred, valid_acc, _ = compute_accuracy(\n",
    "    use_indices, valid_predictions_of_classifiers, y_valid\n",
    ")\n",
    "# テストデータに対する正解率を計算\n",
    "test_pred, test_acc, _ = compute_accuracy(\n",
    "    use_indices, test_predictions_of_classifiers, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、結果を使用して精度の計算を行います。QBoostの結果が単純な多数決の結果を超えていることを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    print(f\"QBoost(step 1) class {i}: {test_acc[i]*100} %\")  # クラスごとの正解率を表示\n",
    "    results[\"QBoost(step 1)\"][f\"class {i}\"] = test_acc[i] * 100\n",
    "\n",
    "results[\"QBoost(step 1)\"][\"num_classifiers\"] = sum(\n",
    "    len(use_indices[i]) for i in range(num_classes)\n",
    ")  # 使用した分類器の数\n",
    "print(results[\"QBoost(step 1)\"][\"num_classifiers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終的な出力は以下の関数によって計算されます。\n",
    "冒頭の単純な多数決と同様に、データがラベルiである、と予測した分類器が最も多いラベルを分類器全体の出力とみなして正解率を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(model_predictions, valid_acc, y_true):\n",
    "    \"\"\"各ラベルに対応する分類器の予測の多数決をとり、最終的な出力と正解率を計算\"\"\"\n",
    "    m_vote = np.argmax(model_predictions, axis=0)\n",
    "    accuracy = metrics.accuracy_score(y_true=y_true, y_pred=m_vote)\n",
    "    return np.array(m_vote), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "m_vote, accuracy = model_output(test_pred, valid_acc, y_test_tmp)\n",
    "print(f\"QBoost(step 1): {accuracy*100} %\")\n",
    "results[\"QBoost(step 1)\"][\"Total\"] = accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2段階目：QBoost による分類器の修正\n",
    "\n",
    "さて前置きが長くなりましたがQBoostを実行していきます。まずはQBoostがどのような方針でどのように定式化されるかを見ていきます。\n",
    " \n",
    "QBoostでは\n",
    "1. 全ての分類器の中から最も高い精度が得られる組み合わせを求めてそれを使用する (ノイズとなる余計な分類器を除外する)\n",
    "2. 間違いが多い分類器をこれまでの分類結果に応じて更新する (ブースティングの思想) \n",
    "\n",
    "といった操作を繰り返します。 具体的には、以下のような操作となります。\n",
    "\n",
    "まず、弱分類器からいくつかを選ぶ操作の結果として得られる新しい分類器を$H(x)$とし、先ほどと同様に定義します。\n",
    " \n",
    "$$ H(x) = {\\rm sign}\\left(\\sum_{i=1}^{C}s_i h_i(x)\\right)$$\n",
    "\n",
    "\n",
    "$C$は分類器の数、$h_i(x) \\in \\{-1, 1\\}$は弱分類器、$s_i \\in \\{0, 1\\}$はバイナリ変数です。\n",
    "\n",
    "ここで、上の式のバイナリ変数$s$を最適化するために最小化すべき関数は以下のようになります。\n",
    "\n",
    "$$ s_{min} = \\mathop{\\rm arg~min}\\limits_{s} \\sum_{j=1}^{N_{\\textit{train}}}\\left(y_j\n",
    "\\sum_{i=1}^{C}s_ih_i(x_j)-1\\right)^2 + P\\sum_{i=1}^{C}s_i$$\n",
    "\n",
    "$N_{train}$は学習データの数、$y_j \\in \\{-1, 1\\}$はデータ$x_j$に対するラベルで、$P$はバイナリ変数に対するペナルティ(定数)です。\n",
    "\n",
    "次に、$H(x)$を定める過程で選ばれなかった弱分類器を重みづけした学習データで学習しなおすことにより更新します。\n",
    "このとき、$j$番目の学習データの重み$d_j$は、分類器$H(x)$において$j$番目の学習データを誤分類する弱分類器が多いほど大きく重みづけるように、\n",
    "\n",
    "$$\n",
    "d_j \\leftarrow d_j\\times\\left(y_j\n",
    "\\sum_{i=1}^{C}s_ih_i(x_j)-1\\right)^2\n",
    "$$\n",
    "\n",
    "のようにして更新します。実際には、オーバーフローやアンダーフローを防ぐために、$\\sum_{i=1}^Cd_j=1$となるように正規化して実装します。\n",
    "\n",
    "次のループでは、このようにして更新された弱分類器と$H(x)$に含まれる弱分類器 (今回は合計100個あります) を用いて、再度弱分類器の最適な組み合わせを求め、選ばれなかった弱分類器を更新することになります。\n",
    "\n",
    "以上が二値分類を行う場合のQBoostの大まかな流れです。\n",
    "今回は、QBoostの多クラス分類への拡張として、一対多の二値分類を行う分類器を組み合わせることを考えます。\n",
    "\n",
    "各クラスに対して、そのデータが自分のクラスに属しているかどうかを判別する2値分類器を用意し、その出力を総合して分類器全体の出力とします。\n",
    "具体的には、クラスごとの分類器の出力からデータの予測クラスが一意に定まる場合はそれを出力し、そうでない場合はバリデーションデータに対する精度が最も高いクラスの分類器を優先します。\n",
    "\n",
    "定式化に関して、先ほど紹介したシンプルな手法との差分は、パラメーター$d$を使用するか否かだけなので、多クラス拡張に関する説明・数式は省略します。\n",
    "\n",
    "参考文献：[QBoost: Large Scale Classifier Training with\n",
    "Adiabatic Quantum Optimization](http://proceedings.mlr.press/v25/neven12/neven12.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、パラメーター$d$と弱学習器を反復ごと更新する必要があるため、その処理を行う関数を次のセルで定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(\n",
    "    d_inner,\n",
    "    best_idxs,\n",
    "    use_idxs,\n",
    "    classifiers,\n",
    "    valid_predictions_of_classifiers,\n",
    "    test_predictions_of_classifiers,\n",
    "):\n",
    "    \"\"\"重み付けパラメーターdの更新と、最適化の結果使用しないとされた弱分類器の更新\"\"\"\n",
    "    # 重み付けパラメーターdを更新\n",
    "    for l in range(num_classes):\n",
    "        d_broadcast = np.broadcast_to(\n",
    "            d_inner[:, l], (len(best_idxs[l]), len(d_inner[:, l]))\n",
    "        ).copy()\n",
    "        tmp = (\n",
    "            y_train[l]\n",
    "            * np.sum(\n",
    "                d_broadcast * train_predictions_of_classifiers[best_idxs[l]][:, l, :],\n",
    "                axis=0,\n",
    "            )\n",
    "            - 1\n",
    "        ) ** 2\n",
    "        d_inner[:, l] *= tmp\n",
    "        if np.sum(d_inner[:, l]) == 0:\n",
    "            continue\n",
    "        d_inner[:, l] /= np.sum(d_inner[:, l])\n",
    "\n",
    "    # Update classifier dictionary\n",
    "    # 選択されていない分類器を、データに重み付けをした上で更新する\n",
    "    tmp = np.array(np.nonzero(use_idxs))\n",
    "    for c in range(tmp.shape[-1]):\n",
    "        i, l = tmp[:, c]\n",
    "        classifier = classifiers[l][i]\n",
    "        sample_indices = np.random.choice(np.arange(X_train.shape[0]), num_samples)\n",
    "        classifier.fit(\n",
    "            X=X_train[sample_indices],\n",
    "            y=y_train[i, sample_indices],\n",
    "            sample_weight=d_inner[sample_indices, i],\n",
    "        )\n",
    "        test_predictions_of_classifiers[l][i] = classifier.predict(X_test)\n",
    "        valid_predictions_of_classifiers[l][i] = classifier.predict(X_valid)\n",
    "\n",
    "    return (\n",
    "        d_inner,\n",
    "        classifiers,\n",
    "        valid_predictions_of_classifiers,\n",
    "        test_predictions_of_classifiers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、ハイパーパラメーターの設定と、変数の初期化を行います。\n",
    "ハイパーパラメーターとは、アルゴリズム実行前に人が設定する必要のあるパラメーターを指します。通常、ハイパーパラメーターはブラックボックス最適化手法を用いて（用意した候補の中で）最適なものが選択されますが、今回は適当に決め打ちしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 1000  # 最大反復回数\n",
    "EPS = 1e-8  # パラメータdのスケーリングチェック用\n",
    "\n",
    "prev_acc = -1\n",
    "best_acc = 0\n",
    "best_idxs = None\n",
    "best_T = -1\n",
    "best_lam = None\n",
    "\n",
    "\n",
    "# initialization\n",
    "d_inner = np.full((len(X_train), num_classes), 1 / len(X_train))\n",
    "T_inner = 0\n",
    "lam = np.arange(0.001, penalty / 10, 0.01)  # ペナルティ項の係数\n",
    "use_idxs = np.ones((num_classes, num_classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のことを踏まえると、QBoostは以下のコードによって実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "for _iter in range(MAX_ITER):\n",
    "    assert (\n",
    "        abs(np.sum(d_inner, axis=0) - 1) < EPS\n",
    "    ).all()  # 重み付け用のパラメーターがきちんとスケーリングされているかチェック\n",
    "    for penalty in lam:\n",
    "        print(\"iteration :\", _iter, \"lambda =\", penalty)\n",
    "        print(f\"Best : {best_acc*100}%\")\n",
    "\n",
    "        # 変数の用意・学習データに対する推論結果の計算\n",
    "        spins, train_predictions_of_classifiers = preprocess(classifiers)\n",
    "        # QUBOモデルの作成\n",
    "        f = createQUBO(spins, penalty, train_predictions_of_classifiers)\n",
    "        # 求解・解の取り出し\n",
    "        temporal_idxs = solve(f, spins)\n",
    "        # クラスラベルごとの正解率を計算\n",
    "        predictions_qboost, valid_acc, accept = compute_accuracy(\n",
    "            temporal_idxs, valid_predictions_of_classifiers, y_valid\n",
    "        )\n",
    "\n",
    "        if not accept:\n",
    "            # 最適化の結果、あるクラスの分類器を使わないことが最適とされた場合は処理を終了し次のループへ進む\n",
    "            continue\n",
    "        if num_classes > 2:  # 統合した結果を計算\n",
    "            m_vote, accuracy = model_output(predictions_qboost, valid_acc, y_valid_tmp)\n",
    "\n",
    "        if (\n",
    "            accuracy >= best_acc\n",
    "        ).all():  # 正解率が向上した場合、得られた解を最良解とする\n",
    "            best_acc = accuracy\n",
    "            best_idxs = temporal_idxs\n",
    "            best_T = sum(len(temporal_idxs[i]) for i in range(num_classes))\n",
    "            for i in range(num_classes):\n",
    "                use_idxs[i, best_idxs[i]] = 0\n",
    "                best_lam = penalty\n",
    "\n",
    "    if (prev_acc >= best_acc).all():  # 最良解の更新が止まったタイミングで処理を終了する\n",
    "        print(\n",
    "            \"Finish!\",\n",
    "            f\"Best acculacy = {best_acc*100}%, number of classifiers = {best_T}, best lambda = {best_lam}\",\n",
    "        )\n",
    "        break\n",
    "    prev_acc = best_acc\n",
    "\n",
    "    # 重みづけパラメーターと、未使用の分類器を更新\n",
    "    (\n",
    "        d_inner,\n",
    "        classifiers,\n",
    "        valid_predictions_of_classifiers,\n",
    "        test_predictions_of_classifiers,\n",
    "    ) = update_parameters(\n",
    "        d_inner,\n",
    "        best_idxs,\n",
    "        use_idxs,\n",
    "        classifiers,\n",
    "        valid_predictions_of_classifiers,\n",
    "        test_predictions_of_classifiers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、最適化の結果を確認します。まずはクラスごとの正解率を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred, valid_acc, _ = compute_accuracy(\n",
    "    best_idxs, valid_predictions_of_classifiers, y_valid\n",
    ")\n",
    "test_pred, test_acc, _ = compute_accuracy(\n",
    "    best_idxs, test_predictions_of_classifiers, y_test\n",
    ")\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print(f\"QBoost class {i}: {test_acc[i]*100} %\")\n",
    "    results[\"QBoost(step 2)\"][f\"class {i}\"] = test_acc[i] * 100\n",
    "    # print(\"precision\", metrics.precision_score(y_true=y_test[i], y_pred=predictions_qboost[i])*100)\n",
    "    # print(\"recall\", metrics.recall_score(y_true=y_test[i], y_pred=predictions_qboost[i])*100)\n",
    "\n",
    "print(best_T)\n",
    "results[\"QBoost(step 2)\"][\"num_classifiers\"] = best_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、各クラスに対応する分類器の出力を統合した場合の正解率を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_classes > 2:\n",
    "    m_vote, accuracy = model_output(test_pred, valid_acc, y_test_tmp)\n",
    "    print(f\"QBoost(step 2): {accuracy*100} %\")\n",
    "    results[\"QBoost(step 2)\"][\"Total\"] = accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 単純な問題を扱ったためQBoostでの結果が単純な多数決より悪くなる場合もありますが、ご了承ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "ナイーブな手法、ノイズとなる分類器を除去する手法、QBoostの結果をまとめると以下のようになります。 \n",
    "この結果から QBoost により分類精度を改善できていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.T"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
