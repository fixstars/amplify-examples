{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMQA によるモデル超電導材料の探索\n",
    "\n",
    "FMQA の効果的な活用方法を理解していただくために、本サンプルコードでは、疑似的な材料から構成される超電導材料の探索を例題として取り扱います。\n",
    "\n",
    "なお、本 FMQA サンプルコードでは、非線形なモデル代数式に基づいて、材料探索を行いますが、モデル代数式の代わりに、高精度なシミュレーションや実験計測結果を用いても同様のステップで様々な材料探索に関する FMQA 最適化を行うことが可能で、その場合、本サンプルコードをほぼそのまま活用いただけます。\n",
    "\n",
    "ブラックボックス最適化や FMQA の基本知識については、『[量子アニーリング・イジングマシンによるブラックボックス最適化](./fmqa_0_algebra.ipynb)』をご覧ください。\n",
    "\n",
    "また、FMQA を活用したより応用的なモデルケースとして、\n",
    "\n",
    "- [FMQA による化学プラントにおける生産量最大化](./fmqa_2_reactor.ipynb)\n",
    "- [FMQA と流体シミュレーションによる翼形状の最適化](./fmqa_3_aerofoil.ipynb)\n",
    "\n",
    "も紹介されていますので、ご覧ください。\n",
    "\n",
    "本ノートブックは、以下の構成となっています。\n",
    "\n",
    "- 1\\. [問題設定](#1)\n",
    "  - 1.1\\. [超電導材料の探索シナリオ](#1_1)\n",
    "  - 1.2\\. [乱数の初期化](#1_2)\n",
    "  - 1.3\\. [臨界温度モデルの定義](#1_3)\n",
    "- 2\\. [FMQA のプログラム実装](#2)\n",
    "  - 2.1\\. [クライアントの設定](#2_1)\n",
    "  - 2.2\\. [PyTorch による FM の実装](#2_2)\n",
    "  - 2.3\\. [初期教師データの作成](#2_3)\n",
    "  - 2.4\\. [FMQA サイクルの実行クラス](#2_4)\n",
    "- 3\\. [FMQA 実行例](#3)\n",
    "  - 3.1\\. [FMQA による最高臨界温度を実現する材料探索](#3_1)\n",
    "  - 3.2\\. [FMQA 最適化過程における目的関数値の推移](#3_2)\n",
    "  - 3.3\\. [本 FMQA サンプルコード実行例](#3_3)\n",
    "- 発展：[より理解を深めるための練習問題](#4)\n",
    "  - [発展1](#4_1)\n",
    "  - [発展2](#4_2)\n",
    "  - [発展3](#4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1\\. 問題設定\n",
    "\n",
    "<a id=\"1_1\"></a>\n",
    "### 1.1\\. 超電導材料の探索シナリオ\n",
    "\n",
    "超電導技術は、リニアモーターカーに代表される輸送分野や計測分野、エネルギー分野においての活用が期待される技術で、現在様々な超電導を実現する超電導材料の開発が行われています。\n",
    "\n",
    "しかし、現在確認されている超電導材料において、一般的に超電導状態に転移する温度（臨界温度）は絶対温度 0 K（ケルビン）付近であるため、超電導の活用には高コストな冷却が必要で、現状、社会的な応用は限られています。したがって、高温超電導体の探索が喫緊の課題です。\n",
    "\n",
    "通常、超電導を実現する材料の探索には、数々の材料を選択・合成し、その合成材料の臨界温度を計測により評価するというプロセスを繰り返し、より高温の臨界温度を実現する合成対象の材料を同定する、という試行錯誤を行います。この合成と臨界温度の評価は非常に高時間コストと考えられます。この探索に対してブラックボックス最適化手法の1つである FMQA を活用し、比較的少ない評価回数で最適解に近い材料の組み合わせを求めます。\n",
    "\n",
    "本サンプルコードでは、FMQA による材料探索の解説のために、疑似的な材料から構成される超電導材料の探索を例題として取り扱い、臨界温度の評価には模擬的な臨界温度モデルを用います。従って、以下で紹介する臨界温度モデル及び取得される材料の組み合わせは、必ずしも物理的な正確性を持たないことに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_2\"></a>\n",
    "### 1.2\\. 乱数の初期化\n",
    "\n",
    "実行毎にモデル出力や機械学習結果が変わらないようにするための、乱数seed値の初期化関数 `seed_everything()` を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_3\"></a>\n",
    "### 1.3\\. 臨界温度モデルの定義\n",
    "\n",
    "\n",
    "本サンプルコードでは、$D$ 種類の材料から、いくつかの材料を組み合わせを上手く選択し、それらの合成で生成された超電導材料の臨界温度を最大化する最適化を実施します。\n",
    "\n",
    "一般的に、臨界温度は実験計測で評価するしかなく、その実施には毎回比較的大きなコスト（時間・費用）が必要です。\n",
    "\n",
    "本サンプルコードでは、臨界温度の計測の代わりに、以下の模擬的な臨界温度モデル `supercon_temperature()` を用いて評価を行いますが、この関数はあくまでも実験の代用であり、その中身やパラメータについては未知であるとして扱い、`supercon_temperature()` を呼ぶ回数にも制限があるものとして取り扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 臨界温度計算のための種々の係数テーブルを乱数により決定する関数。\n",
    "\n",
    "\n",
    "def set_properties(size):\n",
    "    mu, sigma, ratio = 0.0, 1.0, 0.2\n",
    "    table1 = np.random.rand(size) * 1e5 * (0.1 * math.log(size) - 0.23)\n",
    "    table2 = np.random.lognormal(mu, sigma, size) * ratio\n",
    "    table3 = np.random.lognormal(mu, sigma, size) * ratio\n",
    "    return table1, table2, table3\n",
    "\n",
    "\n",
    "# 与えられた材料の組み合わせ x (numpyの1次元配列) と各材料の物性値から、合成される超電導物質の臨界温度を計算するモデル関数。\n",
    "\n",
    "\n",
    "def supercon_temperature(x, debye_table, state_table, interaction_table):\n",
    "    debye_temperature = np.sum(x * debye_table) / np.sum(x)\n",
    "    state_density = np.sum(x * state_table) / np.sum(x)\n",
    "    interaction = np.sum(x * interaction_table) / np.sum(x)\n",
    "    crit_temp = debye_temperature * math.exp(-1.0 / state_density / interaction)\n",
    "    return crit_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では、上記で定義した臨界温度のモデル関数 `supercon_temperature(x)` を用いて、ランダムに選択した材料から合成される超電導材料の臨界温度を評価します。ここで、`D` は選択対象となる材料の数で、入力のバイナリベクトル `x` は、サイズ `D` のバイナリベクトルです。\n",
    "\n",
    "例えば、5種類の材料から最初と最後の材料を選択して合成する、という場合、入力ベクトルは `x = [1, 0, 0, 0, 1]` となります。この場合、選択の仕方（組み合わせ）は、$2^5-1=31$ 通りあります。\n",
    "\n",
    "`D = 100` の場合、組み合わせの数は、$10^{30}$ 通り程度存在し、全探索的な方法は困難と考えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()  # 乱数シードの初期化\n",
    "D = 100  # 決定変数のサイズ（材料選択肢の数）\n",
    "debye_temperature_table, state_density_table, interaction_table = set_properties(\n",
    "    D\n",
    ")  # 係数テーブルの準備\n",
    "\n",
    "# ランダムな入力 x で supercon_temp() 関数を n_cycle 回評価し、得られた最高臨界温度と平均臨界温度を出力。\n",
    "n_cycle = 100\n",
    "t_max = 0.0  # 臨界温度の最大値を格納する変数\n",
    "t_mean = 0.0  # 臨界温度の平均値を計算する変数\n",
    "for i in range(n_cycle):\n",
    "    x = np.random.randint(0, 2, D)\n",
    "    if np.sum(x) == 0:\n",
    "        continue\n",
    "    t_c = supercon_temperature(\n",
    "        x, debye_temperature_table, state_density_table, interaction_table\n",
    "    )\n",
    "    if t_max < t_c:\n",
    "        t_max = t_c\n",
    "    t_mean += t_c\n",
    "t_mean /= n_cycle\n",
    "\n",
    "print(f\"Max. critical temperature: {t_max:.2f} K\")\n",
    "print(f\"Mean critical temperature: {t_mean:.2f} K\")\n",
    "print(f\"{n_cycle=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2\\. FMQA のプログラム実装\n",
    "\n",
    "ここでは、FMQA のプログラム実装を行います。FMQA部分の実装は、『[量子アニーリング・イジングマシンによるブラックボックス最適化](./fmqa_0_algebra.ipynb)』と同一ですので、詳細はそちらの解説をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_1\"></a>\n",
    "### 2.1\\. クライアントの設定\n",
    "\n",
    "Amplify のクライアントを作成し、必要なパラメータを設定します。 以下では、イジングマシンによる一度の探索時間を1秒に設定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify.client import FixstarsClient\n",
    "\n",
    "client = FixstarsClient()\n",
    "client.parameters.timeout = 1000  # タイムアウト1秒\n",
    "# client.token = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # ローカル環境等で使用する場合は、Amplify AEのアクセストークンを入力してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_2\"></a>\n",
    "### 2.2\\. PyTorch による FM の実装\n",
    "\n",
    "FM の学習と推論を PyTorch で行います。`TorchFM` クラスでは、機械学習モデルとしての獲得関数 $g(\\boldsymbol{x})$ を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TorchFM(nn.Module):\n",
    "    def __init__(self, d: int, k: int):\n",
    "        super().__init__()\n",
    "        self.V = nn.Parameter(torch.randn(d, k), requires_grad=True)\n",
    "        self.lin = nn.Linear(d, 1)  # 右辺第1項及び2項は全結合ネットワーク\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x, self.V).pow(2).sum(1, keepdim=True)\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(1, keepdim=True)\n",
    "        out_inter = 0.5 * (out_1 - out_2)\n",
    "        out_lin = self.lin(x)\n",
    "        out = out_inter + out_lin\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、入出力データから FM を機械学習する関数 `train()` を定義します。一般的な機械学習と同様に、教師データを学習データと検証データに分割し、学習データを用いてパラメータの最適化、検証データを用いて学習中のモデル検証を行います。`train()` 関数は、検証データに対して最も予測精度の高かったモデルを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def train(\n",
    "    X,\n",
    "    y,\n",
    "    model_class=None,\n",
    "    model_params=None,\n",
    "    batch_size=1024,\n",
    "    epochs=3000,\n",
    "    criterion=None,\n",
    "    optimizer_class=None,\n",
    "    opt_params=None,\n",
    "    lr_sche_class=None,\n",
    "    lr_sche_params=None,\n",
    "):\n",
    "    X_tensor, y_tensor = (\n",
    "        torch.from_numpy(X).float(),\n",
    "        torch.from_numpy(y).float(),\n",
    "    )\n",
    "    indices = np.array(range(X.shape[0]))\n",
    "    indices_train, indices_valid = train_test_split(\n",
    "        indices, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_set = TensorDataset(X_tensor[indices_train], y_tensor[indices_train])\n",
    "    valid_set = TensorDataset(X_tensor[indices_valid], y_tensor[indices_valid])\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "        \"valid\": DataLoader(valid_set, batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    optimizer = optimizer_class(model.parameters(), **opt_params)\n",
    "    if lr_sche_class is not None:\n",
    "        scheduler = lr_sche_class(optimizer, **lr_sche_params)\n",
    "    best_score = 1e18\n",
    "    for epoch in range(epochs):\n",
    "        losses = {\"train\": 0.0, \"valid\": 0.0}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            for batch_x, batch_y in loaders[phase]:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch_x).T[0]\n",
    "                loss = criterion(out, batch_y)\n",
    "                losses[phase] += loss.item() * batch_x.size(0)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "            losses[phase] /= len(loaders[phase].dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            if best_score > losses[\"valid\"]:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_score = losses[\"valid\"]\n",
    "        if lr_sche_class is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_3\"></a>\n",
    "### 2.3\\. 初期教師データの作成\n",
    "\n",
    "入力値 $\\boldsymbol{x}$ に対して目的関数 $f(\\boldsymbol{x})$ を評価し、$N_0$個の入出力ペア（初期教師データ）を作成します。ここでの入力値 $\\boldsymbol{x}$ の決め方は様々ですが、乱数を用いたり、現象に対する知見に基づき機械学習に適した値を用いたりします。過去に実施した実験やシミュレーションの結果から、教師データを構築しても構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_data(D: int, N0: int, true_func):\n",
    "    assert N0 < 2**D\n",
    "    # N0個の入力値を乱数を用いて取得\n",
    "    X = np.random.randint(0, 2, size=(N0, D))\n",
    "    # 取得した入力値のうち重複しているものを除外し、除外した分の入力値を乱数を用いて追加\n",
    "    X = np.unique(X, axis=0)\n",
    "    while X.shape[0] != N0:\n",
    "        X = np.vstack((X, np.random.randint(0, 2, size=(N0 - X.shape[0], D))))\n",
    "        X = np.unique(X, axis=0)\n",
    "    y = np.zeros(N0)\n",
    "    # N0個の入力値に対応する出力値を目的関数を評価して取得\n",
    "    for i in range(N0):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Generating {i}-th training data set.\")\n",
    "        y[i] = true_func(X[i])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_4\"></a>\n",
    "### 2.4\\. FMQA サイクルの実行クラス\n",
    "\n",
    "`FMQA.cycle()` では、事前に準備した初期教師データを用い、FMQA サイクルを $N-N_0$ 回実施します。`FMQA.step()` は、FMQA を1サイクルのみ行う関数で、`FMQA.cycle()` から $N-N_0$ 回呼び出されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplify import (\n",
    "    Solver,\n",
    "    BinarySymbolGenerator,\n",
    "    sum_poly,\n",
    "    BinaryMatrix,\n",
    "    BinaryQuadraticModel,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "class FMQA:\n",
    "    def __init__(self, D: int, N: int, N0: int, k: int, true_func, solver) -> None:\n",
    "        assert N0 < N\n",
    "        self.D = D\n",
    "        self.N = N\n",
    "        self.N0 = N0\n",
    "        self.k = k\n",
    "        self.true_func = true_func\n",
    "        self.solver = solver\n",
    "        self.y = None\n",
    "\n",
    "    # 教師データに基づいて N-N0 回のFMQAを教師データを追加しながら繰り返し実施するメンバー関数\n",
    "    def cycle(self, X, y, log=False) -> np.ndarray:\n",
    "        print(f\"Starting FMQA cycles...\")\n",
    "        pred_x = X[0]\n",
    "        pred_y = 1e18\n",
    "        for i in range(self.N - self.N0):\n",
    "            print(f\"FMQA Cycle #{i} \", end=\"\")\n",
    "            try:\n",
    "                x_hat = self.step(X, y)\n",
    "            except RuntimeError:\n",
    "                sys.exit(f\"Unknown error, i = {i}\")\n",
    "            # x_hat として既に全く同じ入力が教師データ内に存在する場合、その周辺の値を x_hat とする。\n",
    "            is_identical = True\n",
    "            while is_identical:\n",
    "                is_identical = False\n",
    "                for j in range(i + self.N0):\n",
    "                    if np.all(x_hat == X[j, :]):\n",
    "                        change_id = np.random.randint(0, self.D, 1)\n",
    "                        x_hat[change_id.item()] = 1 - x_hat[change_id.item()]\n",
    "                        if log:\n",
    "                            print(f\"{i=}, Identical x is found, {x_hat=}\")\n",
    "                        is_identical = True\n",
    "                        break\n",
    "            # hat{x} で目的関数 f() を評価\n",
    "            y_hat = self.true_func(x_hat)\n",
    "            # 最適点近傍における入出力ペア [x_hat, y_hat] を教師データに追加\n",
    "            X = np.vstack((X, x_hat))\n",
    "            y = np.append(y, y_hat)\n",
    "            # 目的関数の評価値が最小値を更新したら、その入出力ペアを [pred_x, pred_y] へコピー\n",
    "            if pred_y > y_hat:\n",
    "                pred_y = y_hat\n",
    "                pred_x = x_hat\n",
    "                print(f\"variable updated, {pred_y=}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "            # 全ての入力を全探索済みの場合は、for文を抜ける\n",
    "            if len(y) >= 2**self.D:\n",
    "                print(f\"Fully searched at {i=}. Terminating FMQA cycles.\")\n",
    "                break\n",
    "        self.y = y\n",
    "        return pred_x\n",
    "\n",
    "    # 1回のFMQAを実施するメンバー関数\n",
    "    def step(self, X, y) -> np.ndarray:\n",
    "        # FM を機械学習\n",
    "        model = train(\n",
    "            X,\n",
    "            y,\n",
    "            model_class=TorchFM,\n",
    "            model_params={\"d\": self.D, \"k\": self.k},\n",
    "            batch_size=8,\n",
    "            epochs=2000,\n",
    "            criterion=nn.MSELoss(),\n",
    "            optimizer_class=torch.optim.AdamW,\n",
    "            opt_params={\"lr\": 1},\n",
    "        )\n",
    "        # 学習済みモデルから、FM パラメータの抽出\n",
    "        v, w, w0 = list(model.parameters())\n",
    "        v = v.detach().numpy()\n",
    "        w = w.detach().numpy()[0]\n",
    "        w0 = w0.detach().numpy()[0]\n",
    "        # ここから量子アニーリング・イジングマシンによる求解を実施\n",
    "        gen = BinarySymbolGenerator()  # BinaryPoly の変数ジェネレータを宣言\n",
    "        q = gen.array(self.D)  # BinaryPoly から決定変数の作成\n",
    "        cost = self.__FM_as_QUBO(q, w0, w, v)  # FM パラメータから QUBO として FM を定義\n",
    "        result = self.solver.solve(cost)  # 目的関数を Amplify のソルバーに受け渡し\n",
    "        if len(result.solutions) == 0:\n",
    "            raise RuntimeError(\"No solution was found.\")\n",
    "        values = result.solutions[0].values\n",
    "        q_values = q.decode(values)\n",
    "        return q_values\n",
    "\n",
    "    # FM パラメータから QUBO として FM を定義する関数。前定義の TorchFM クラスと同様に、g(x) の関数形通りに数式を記述。\n",
    "    def __FM_as_QUBO(self, x, w0, w, v):\n",
    "        lin = w0 + (x.T @ w)\n",
    "        D = w.shape[0]\n",
    "        out_1 = sum_poly(self.k, lambda i: sum_poly(D, lambda j: x[j] * v[j, i]) ** 2)\n",
    "        # 次式において、x[j] はバイナリ変数なので、x[j] = x[j]^2 であることに注意。\n",
    "        out_2 = sum_poly(\n",
    "            self.k, lambda i: sum_poly(D, lambda j: x[j] * v[j, i] * v[j, i])\n",
    "        )\n",
    "        return lin + (out_1 - out_2) / 2\n",
    "\n",
    "    \"\"\"上記の __FM_as_QUBO で用いられている sum_poly は、計算速度やメモリの観点から非効率。\n",
    "    一般的に決定変数の相互作用項が非ゼロである FM の場合、BinaryMatrix を使う次の書き方が効率的。\n",
    "    ここで、BinaryMatrixでの2次項は、上三角行列で表される非対角項に対応するため、FM式の2次の項に\n",
    "    対する x(1/2) は不要。また、上の __FM_as_QUBO（sum_poly を使う実装）と関数のシグネチャを\n",
    "    合わせるために、x を引数に取っているが、BinaryMatrix を使う本実装では本来は不要。\n",
    "    def __FM_as_QUBO(self, x, w0, w, v):\n",
    "        out_1_matrix = v @ v.T\n",
    "        out_2_matrix = np.diag((v * v).sum(axis=1))\n",
    "        matrix = BinaryMatrix(out_1_matrix - out_2_matrix + np.diag(w))\n",
    "        # 定数項 w0 を忘れずに BinaryQuadraticModel の2つ目の引数に入れる。\n",
    "        model = BinaryQuadraticModel(matrix, w0)\n",
    "        return model\n",
    "    \"\"\"\n",
    "\n",
    "    # 初期教師データ及び各 FMQA サイクル内で実施した i 回の目的関数評価値の履歴をプロットする関数\n",
    "    def plot_history(self):\n",
    "        assert self.y is not None\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        plt.plot(\n",
    "            [i for i in range(self.N0)],\n",
    "            self.y[: self.N0],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            color=\"b\",\n",
    "        )  # 初期教師データ生成時の目的関数評価値（ランダム過程）\n",
    "        plt.plot(\n",
    "            [i for i in range(self.N0, self.N)],\n",
    "            self.y[self.N0 :],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            color=\"r\",\n",
    "        )  # FMQA サイクル時の目的関数評価値（FMQA サイクル過程）\n",
    "        plt.xlabel(\"i-th evaluation of f(x)\", fontsize=18)\n",
    "        plt.ylabel(\"f(x)\", fontsize=18)\n",
    "        plt.tick_params(labelsize=18)\n",
    "        return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3\\. FMQA 実行例\n",
    "\n",
    "<a id=\"3_1\"></a>\n",
    "### 3.1\\. FMQA による最高臨界温度を実現する材料探索\n",
    "\n",
    "それでは実装した FMQA 及びモデル関数を用いて、材料探索を行います。今回は、モデルから計算される臨界温度を最大化するので、目的関数として、臨界温度の負値を返すように実装し、この値を最小化するように FMQA を実施します。\n",
    "\n",
    "以下では、目的関数を評価できる回数 $N$ を100回、そのうち初期データの生成のための評価回数 $N_0=60$ 回としています。従って、以下の例では、$N-N_0=40$ 回、FMQA のサイクル（機械学習、量子アニーリング・イジングマシンによる最適解の求解、目的関数の評価）を実施します。この設定では、FMQA のサイクルが全て終了するまでおよそ5～10分程度の時間がかかりますので、ご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()  # 乱数シードの初期化\n",
    "D = 100  # 決定変数のサイズ（材料選択肢の数）\n",
    "\n",
    "# 係数テーブルの準備\n",
    "debye_temperature_table, state_density_table, interaction_table = set_properties(D)\n",
    "\n",
    "# 目的関数。臨界温度を最大化したいので、臨界温度の負値を返し、この値を最小化するような材料の選び方を FMQA により最適化\n",
    "\n",
    "\n",
    "def true_func(x):\n",
    "    if np.sum(x) == 0:\n",
    "        return 0\n",
    "    return -supercon_temperature(\n",
    "        x, debye_temperature_table, state_density_table, interaction_table\n",
    "    )\n",
    "\n",
    "\n",
    "N = 100  # 関数を評価できる回数\n",
    "N0 = 60  # 初期教師データのサンプル数\n",
    "k = 20  # FMにおけるベクトルの次元（ハイパーパラメータ）\n",
    "\n",
    "# client：先に作成した Amplify クライアント\n",
    "solver = Solver(client)\n",
    "# 初期教師データの生成\n",
    "X, y = gen_training_data(D, N0, true_func)\n",
    "\n",
    "# FMQA のインスタンス化\n",
    "fmqa_solver = FMQA(D, N, N0, k, true_func, solver)\n",
    "# FMQA サイクルの実行\n",
    "pred_x = fmqa_solver.cycle(X, y)\n",
    "# 最適化結果の出力\n",
    "print(\"pred x:\", pred_x)\n",
    "print(\"pred value:\", true_func(pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3_2\"></a>\n",
    "### 3.2\\. FMQA 最適化過程における目的関数値の推移\n",
    "\n",
    "初期教師データ作成時にランダムに生成した入力値に対して得られた $N_0$​ 個の目標関数値及び $N−N_0$​ サイクルの FMQA 最適化過程における目標関数値の推移を以下にプロットします。\n",
    "\n",
    "それぞれ、青色及び赤色で示されています。FMQA 最適化サイクルにより得られた、その時点での最適と考えられる入力値（赤線）から、最小の目的関数値が次々と更新される様子が示されています。\n",
    "\n",
    "一般的に、`FixstarsClient` で採用されているヒューリスティクスというアルゴリズムの原理上、得られる解に再現性はありませんが、サンプルコード内のパラメータ、$N_0=60$、$N-N_0=40$ で求解された材料選択肢の場合、得られる臨界温度は、およそ 50 K となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fmqa_solver.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3_3\"></a>\n",
    "### 3.3\\. 本 FMQA サンプルコード実行例\n",
    "\n",
    "一般的に、`FixstarsClient` で採用されているヒューリスティクスというアルゴリズムの原理上、得られる解に完全な再現性はありませんが、本サンプルコードを実行した際に得られる、典型的な標準出力及び画像出力を以下に紹介します。※得られる値が異なる場合があります。\n",
    "\n",
    "- 『[3.1\\. FMQA による最高臨界温度を実現する材料探索](#3_1)』に記載の FMQA コードを与えられた条件のまま実行すると、次のような標準出力が FMQA サイクルの進捗とともに逐次出力されます。\n",
    "\n",
    "    ```shell\n",
    "    Generating 0-th training data set.\n",
    "    Generating 10-th training data set.\n",
    "    Generating 20-th training data set.\n",
    "    Generating 30-th training data set.\n",
    "    Generating 40-th training data set.\n",
    "    Generating 50-th training data set.\n",
    "    Starting FMQA cycles...\n",
    "    FMQA Cycle #0 variable updated, pred_y=-18.98476017536205\n",
    "    FMQA Cycle #1 \n",
    "    FMQA Cycle #2 variable updated, pred_y=-25.897204545387414\n",
    "    FMQA Cycle #3 variable updated, pred_y=-30.641568733824826\n",
    "    FMQA Cycle #4 \n",
    "    FMQA Cycle #5 variable updated, pred_y=-33.23380829087865\n",
    "    FMQA Cycle #6 \n",
    "    FMQA Cycle #7 \n",
    "    FMQA Cycle #8 variable updated, pred_y=-40.97929639761995\n",
    "    FMQA Cycle #9 \n",
    "    FMQA Cycle #10 \n",
    "    FMQA Cycle #11 \n",
    "    FMQA Cycle #12 \n",
    "    FMQA Cycle #13 \n",
    "    FMQA Cycle #14 \n",
    "    FMQA Cycle #15 \n",
    "    FMQA Cycle #16 \n",
    "    FMQA Cycle #17 \n",
    "    FMQA Cycle #18 variable updated, pred_y=-42.00895340350797\n",
    "    FMQA Cycle #19 variable updated, pred_y=-47.787495086366945\n",
    "    FMQA Cycle #20 \n",
    "    FMQA Cycle #21 variable updated, pred_y=-52.41427395241357\n",
    "    FMQA Cycle #22 \n",
    "    FMQA Cycle #23 \n",
    "    FMQA Cycle #24 \n",
    "    FMQA Cycle #25 \n",
    "    FMQA Cycle #26 \n",
    "    FMQA Cycle #27 \n",
    "    FMQA Cycle #28 \n",
    "    FMQA Cycle #29 \n",
    "    FMQA Cycle #30 \n",
    "    FMQA Cycle #31 \n",
    "    FMQA Cycle #32 \n",
    "    FMQA Cycle #33 \n",
    "    FMQA Cycle #34 \n",
    "    FMQA Cycle #35 \n",
    "    FMQA Cycle #36 \n",
    "    FMQA Cycle #37 \n",
    "    FMQA Cycle #38 variable updated, pred_y=-55.425491086604936\n",
    "    FMQA Cycle #39 \n",
    "    pred x: [0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
    "    1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
    "    1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n",
    "    1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
    "    1. 0. 1. 1.]\n",
    "    pred value: -55.425491086604936\n",
    "    ```\n",
    "\n",
    "- 『[3.2\\. FMQA 最適化過程における目的関数値の推移](#3_2)』に記載の `fmqa_reactor.plot_history()` による出力画像は次のようになります。\n",
    "\n",
    "  ![history](../figures/fmqa_1_supercon_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "### 発展：より理解を深めるための練習問題\n",
    "\n",
    "<a id=\"4_1\"></a>\n",
    "#### 発展1\n",
    "\n",
    "ランダムな探索で材料の組み合わせを決定する手法をとる場合、FMQA で得られた臨界温度と同レベルの臨界温度を実現する材料の組み合わせを見つけるには、何回程度の試行が必要でしょうか？ [1.3](#1_3) 節の `n_cycle` を変化させて確認してください。\n",
    "\n",
    "- **補足**\n",
    "\n",
    "  1度の機械学習に要する時間を $\\tau_{ML}$、最適解の求解に要する時間を $\\tau_{QA}$、目的関数の評価に要する時間を $\\tau_{eval}$ とすると、一般的に、探索に係る総時間コスト $c_t$ は、次のように記述できます。\n",
    "\n",
    "  $$\n",
    "  c_t = N_0 \\cdot \\tau_{eval} + (N - N_0) \\cdot (\\tau_{ML} + \\tau_{QA} + \\tau_{eval} )\n",
    "  $$\n",
    "\n",
    "  本サンプルコードでは、臨界温度に対してモデルを用いることで、$\\tau_{eval}$ は比較的小さいですが、一般的にブラックボックス最適化を行わなければならない課題では、$\\tau_{eval} \\gg \\tau_{ML}$、$\\tau_{eval} \\gg \\tau_{QA}$ である場合が多いでしょう。その場合、総時間コストは、\n",
    "\n",
    "  $$\n",
    "  c_t \\sim N \\cdot \\tau_{eval}\n",
    "  $$\n",
    "\n",
    "  となります。つまり、今回の場合、例えば、1回の材料合成＋臨界温度計測に1時間必要で、それを単独24時間体制で実施する場合、$N=100$ の探索では 約 4 日、$N=10000$ の探索では約 1 年必要となります。従って、最適化コストを小さくするには、目的関数の評価回数 $N$ を小さくすることがブラックボックス最適化では優先事項です。\n",
    "  \n",
    "  ランダムな探索では、非常に大きな $N$ を用いない限り（つまり $c_t$ が莫大）、一般的には FMQA による最適解に近づいたり、超えたりしないことが示されるでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4_2\"></a>\n",
    "#### 発展2\n",
    "\n",
    "FM 機械学習に関するハイパーパラメータを変更してみましょう。最適化精度や計算時間はどのように変化するでしょうか？\n",
    "\n",
    "- ヒント：以下に抜粋される `FMQA` クラスの `step()` 関数内のモデル呼び出し内におけるパラメータを変更してみてください。（例：エポック数 `epoch` を 0.1 倍にする）\n",
    "  ```python\n",
    "    model = train(\n",
    "        X,\n",
    "        y,\n",
    "        model_class=TorchFM,\n",
    "        model_params={\"d\": self.D, \"k\": self.k},\n",
    "        batch_size=8,\n",
    "        epochs=2000,\n",
    "        criterion=nn.MSELoss(),\n",
    "        optimizer_class=torch.optim.AdamW,\n",
    "        opt_params={\"lr\": 1},\n",
    "    )\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4_3\"></a>\n",
    "#### 発展3\n",
    "\n",
    "FMQA による最適化が活用できそうな業務や身の回りの課題を考えてください。その際、決定変数（入力値）や目的関数は何でしょうか？また目的関数の評価方法はどうなるでしょうか？\n",
    "\n",
    "> 例：次世代ガスタービン発電施設における燃料ブレンド（水素、天然ガス、合成ガス、アンモニア、水蒸気、再循環ガス等）や熱化学条件の最適化。日々の需要に応じた発電出力を担保しながら、燃料調達コストの低減と汚染物質生成の抑制を実現。目的関数は汚染物質の生成量、燃料コスト及び $($電力需要$-$出力$)^2$ で、その評価は、燃料費の（線形）計算と大規模シミュレーション又は実機による計測。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
