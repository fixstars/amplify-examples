{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBoost\n",
    "\n",
    "これはAmplifyを用いたQBoostについてのデモです。\n",
    "\n",
    "## QBoostとは\n",
    "\n",
    "QBoostは機械学習の手法の一つで、アンサンブル学習（Ensemble Learning）といわれる分野に分類されます。より具体的には、ブースティングの思想を取り入れたバギングを行なっています。\n",
    "\n",
    "アンサンブル学習は別々に学習させた分類器（Classifier）を組み合わせて推論させる学習方法のことで、独立に学習した分類器・回帰モデルの出力の多数決もしくは平均を取る手法（バギング）、過去に学習した分類器の出力を元に、学習済みの分類器の弱点を補うように新しい分類器を学習する手法（ブースティング）などがあります。\n",
    "\n",
    "理論的には、バギングを使うことで予測のブレ（分散、バリアンス）を軽減することが期待でき、ブースティングを使用することで予測のズレ（偏り、バイアス）を減少させることが期待できます。バイアスとバリアンスがともに小さいモデルが理想ですが、この二つは互いにトレードオフの関係にあることが知られています。\n",
    "\n",
    "アンサンブル手法の最も単純な実装は各分類器の出力の多数決をとるバギングですが、単純に多数決を取るだけではいわゆる\"良くない\"分類器が紛れ込んでいた場合に、思ったように精度が上がらないなどの問題があります。QBoostはそのような問題を解決するために生まれました。以下では、扱う問題の説明から始め、実際にAmplifyを使用して精度が向上することを確認します。\n",
    "\n",
    "### デモで使用する手法について\n",
    "- 多数決： \n",
    " 弱学習器の推論結果の多数決を全体の推論結果とする \n",
    " `Run(Majority of vote)`ボタンで実行 \n",
    "- QBoost(step 1)： \n",
    " 弱学習器の中から、ノイズとなるような精度が悪い分類器を取り除く \n",
    " `Run(QBoost:step 1)`ボタンで実行 \n",
    "- QBoost(step 2)： \n",
    " QBoost(step 1)のアイデア+精度が悪い分類器を、データに重み付けをした上で更新 \n",
    " `Run(QBoost:step 2)`ボタンで実行\n",
    "\n",
    "## データセットについて\n",
    "\n",
    "\n",
    "今回使用するデータセットは、`scikit-learn`に含まれている`iris_dataset`です。`iris_dataset`とは、計3種類のアヤメとそれに対応する4つの特徴量（花弁の長さ・幅、ガクの長さ・幅）が含まれたデータセットであり、この特徴量を用いてアヤメの分類を行うことが今回の目標です。つまり、教師あり学習による3クラス分類に取り組みます。このデータセットには150個分のアヤメのデータが含まれています。\n",
    "\n",
    "以下が各種類のアヤメの写真です(wikipediaから引用)。パッと見ただけではほとんど違いがわからないと思います。\n",
    "![](./iris_pictures.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from amplify.client import FixstarsClient\n",
    "from amplify import BinarySymbolGenerator, Solver, decode_solution\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import (\n",
    "    Button,\n",
    "    IntSlider,\n",
    "    interactive_output,\n",
    "    VBox,\n",
    "    HBox,\n",
    "    Output,\n",
    "    Label,\n",
    "    Accordion,\n",
    "    IntProgress,\n",
    "    GridBox,\n",
    "    GridspecLayout,\n",
    ")\n",
    "\n",
    "client = FixstarsClient()\n",
    "client.parameters.timeout = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(_num_classifiers=100, _timeout=1000):\n",
    "    global iris_dataset\n",
    "    global timeout\n",
    "    global classifiers\n",
    "    global num_classifiers\n",
    "    global num_samples\n",
    "    global num_classes\n",
    "    global depth\n",
    "    global X_train\n",
    "    global X_test\n",
    "    global X_valid\n",
    "    global y_train\n",
    "    global y_test\n",
    "    global y_valid\n",
    "    global y_train_tmp\n",
    "    global y_test_tmp\n",
    "    global y_valid_tmp\n",
    "    global test_predictions_of_classifiers\n",
    "    global valid_predictions_of_classifiers\n",
    "    global results\n",
    "\n",
    "    results = {\n",
    "        \"多数決\": defaultdict(),\n",
    "        \"QBoost(step 1)\": defaultdict(),\n",
    "        \"QBoost(step 2)\": defaultdict(),\n",
    "    }  # 結果保存用\n",
    "\n",
    "    timeout = _timeout\n",
    "    iris_dataset = load_iris()\n",
    "    data, label = np.array(iris_dataset[\"data\"]), np.array(iris_dataset[\"target\"])\n",
    "    num_classes = len(set(label))\n",
    "    if num_classes == 2:  # データセットに含まれるラベルの種類がふたつなら、分類器は１クラス分あれば良いので調整\n",
    "        num_classes = 1\n",
    "\n",
    "    X_train, X_test, y_train_tmp, y_test_tmp = train_test_split(\n",
    "        data, label, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train_tmp, y_valid_tmp = train_test_split(\n",
    "        X_train, y_train_tmp, test_size=0.25, random_state=0\n",
    "    )\n",
    "\n",
    "    y_train = np.full((num_classes, len(X_train)), -1)\n",
    "    y_test = np.full((num_classes, len(X_test)), -1)\n",
    "    y_valid = np.full((num_classes, len(X_valid)), -1)\n",
    "\n",
    "    def updateLabel(y, tmp):\n",
    "        for i, label in enumerate(tmp):\n",
    "            y[label][i] = 1\n",
    "\n",
    "    updateLabel(y_train, y_train_tmp)\n",
    "    updateLabel(y_test, y_test_tmp)\n",
    "    updateLabel(y_valid, y_valid_tmp)\n",
    "\n",
    "    # fix random seed\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Create weak classifiers\n",
    "    num_classifiers = _num_classifiers\n",
    "    num_samples = 5\n",
    "    depth = 1\n",
    "    classifiers = [\n",
    "        [DTC(splitter=\"random\", max_depth=depth) for _ in range(num_classes)]\n",
    "        for _ in range(num_classifiers)\n",
    "    ]\n",
    "\n",
    "    # Train weak classifiers\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        for i in range(num_classes):\n",
    "            sample_indices = np.random.choice(np.arange(X_train.shape[0]), num_samples)\n",
    "            classifier[i].fit(X=X_train[sample_indices], y=y_train[i, sample_indices])\n",
    "\n",
    "    # Predict & Majority vote\n",
    "    test_predictions_of_classifiers = np.array(\n",
    "        [\n",
    "            [classifier[i].predict(X_test) for i in range(num_classes)]\n",
    "            for classifier in classifiers\n",
    "        ]\n",
    "    )\n",
    "    valid_predictions_of_classifiers = np.array(\n",
    "        [\n",
    "            [classifier[i].predict(X_valid) for i in range(num_classes)]\n",
    "            for classifier in classifiers\n",
    "        ]\n",
    "    )\n",
    "    print(f\"number of classifiers {num_classifiers * num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(X, Y, fig=None, title=None):\n",
    "    global iris_dataset\n",
    "    feature_names = iris_dataset.feature_names\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "    plt.gcf()\n",
    "    # 二次元のグラフを作りたいので特徴量の組み合わせを作る\n",
    "    for i, (x, y) in enumerate(itertools.combinations(range(4), 2)):\n",
    "        # サブグラフ\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        # 各品種はマーカーの色や形を変える\n",
    "        for t, marker, c in zip(range(3), \">ox\", \"rgb\"):\n",
    "            plt.scatter(\n",
    "                X[Y == t, x],\n",
    "                X[Y == t, y],\n",
    "                marker=marker,\n",
    "                c=c,\n",
    "                label=iris_dataset.target_names[t],\n",
    "            )\n",
    "            plt.xlabel(feature_names[x])\n",
    "            plt.ylabel(feature_names[y])\n",
    "    plt.autoscale()\n",
    "    plt.legend()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_majority(Progress):\n",
    "    global classifiers\n",
    "    global X_train\n",
    "    global X_test\n",
    "    global X_valid\n",
    "    global y_train\n",
    "    global y_test\n",
    "    global y_valid\n",
    "    global y_train_tmp\n",
    "    global y_test_tmp\n",
    "    global y_valid_tmp\n",
    "    global test_predictions_of_classifiers\n",
    "    global valid_predictions_of_classifiers\n",
    "\n",
    "    print(f\"Total classifiers: {num_classifiers * num_classes}\")\n",
    "    Progress.value += 1\n",
    "    for i in range(num_classes):\n",
    "        predictions_vote = np.sign(\n",
    "            np.sum(test_predictions_of_classifiers[:, i, :], axis=0)\n",
    "        )\n",
    "        # Calculate accuracy\n",
    "        accuracy = metrics.accuracy_score(y_true=y_test[i], y_pred=predictions_vote)\n",
    "        print(f\"Majority vote of weak classifiers class {i}: {accuracy*100} %\")\n",
    "        results[\"多数決\"][f\"class {i}\"] = accuracy * 100\n",
    "        Progress.value += 2\n",
    "\n",
    "    if num_classes > 2:\n",
    "        tmp = np.sum(test_predictions_of_classifiers, axis=0)\n",
    "        m_vote = np.argmax(tmp, axis=0)\n",
    "        accuracy = metrics.accuracy_score(y_true=y_test_tmp, y_pred=m_vote)\n",
    "        print(f\"Majority vote of weak classifiers: {accuracy*100} %\")\n",
    "        results[\"多数決\"][\"Total\"] = accuracy * 100\n",
    "        results[\"多数決\"][\"num classifiers\"] = num_classes * num_classifiers\n",
    "        Progress.value += 2\n",
    "        plot_features(X_test, np.array(m_vote), title=\"Majority vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(classifiers):\n",
    "    \"\"\"最適化に必要な変数の定義と学習データに対する分類器の出力を計算\"\"\"\n",
    "    # Prepare spins\n",
    "    gen = BinarySymbolGenerator()\n",
    "    spins = gen.array(shape=(num_classifiers, num_classes))\n",
    "\n",
    "    # Obtain predictions for train data\n",
    "    train_predictions_of_classfiers = np.array(\n",
    "        [\n",
    "            [classifier[i].predict(X_train) for i in range(num_classes)]\n",
    "            for classifier in classifiers\n",
    "        ]\n",
    "    )\n",
    "    return spins, train_predictions_of_classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQUBO(spins, penalty, train_predictions_of_classifiers):\n",
    "    \"\"\"QUBOとして最適化する関数を定義\"\"\"\n",
    "    # 各データ、各クラスラベルに対応する分類器について、分類器の総和をとる。\n",
    "    tmp = (np.expand_dims(spins, -1) * train_predictions_of_classifiers).sum(0)\n",
    "    tmp = (y_train * tmp - 1) ** 2\n",
    "    f = tmp.sum()\n",
    "\n",
    "    f += penalty * spins.sum()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(f, spins, solver=None):\n",
    "    \"\"\"Amplify AEを用いて最適化\"\"\"\n",
    "    if solver is None:\n",
    "        client = FixstarsClient()\n",
    "        client.parameters.timeout = 1000\n",
    "        solver = Solver(client)\n",
    "    # Solve QUBO formulation\n",
    "    result = solver.solve(f)\n",
    "    solution = decode_solution(spins, result[0].values)\n",
    "    # 最適化結果の取り出し\n",
    "    use_indices = [\n",
    "        np.where(solution[:, l] == 1)[0].tolist() for l in range(num_classes)\n",
    "    ]\n",
    "    return use_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(use_indices, predictions_of_classifiers, y_true):\n",
    "    \"\"\"与えられたインデックスに対応する分類器による推論結果と正解率を計算\"\"\"\n",
    "    model_predictions = []\n",
    "    accuracy_each_class = []\n",
    "    ACCEPT = True\n",
    "    for i in range(num_classes):\n",
    "        if len(use_indices[i]) == 0:  # 全く使われないクラスの分類器がある場合、結果を採用しない\n",
    "            ACCEPT = False\n",
    "            break\n",
    "        model_predictions.append(\n",
    "            np.sum(predictions_of_classifiers[use_indices[i]][:, i, :], axis=0)\n",
    "        )\n",
    "        accuracy = metrics.accuracy_score(\n",
    "            y_true=y_true[i], y_pred=list(map(np.sign, model_predictions[i]))\n",
    "        )\n",
    "        accuracy_each_class.append(accuracy)\n",
    "    return np.array(model_predictions), np.array(accuracy_each_class), ACCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(model_predictions, valid_acc, y_true):\n",
    "    \"\"\"各ラベルに対応する分類器の予測の多数決をとり、最終的な出力と正解率を計算\"\"\"\n",
    "    m_vote = np.argmax(model_predictions, axis=0)\n",
    "    accuracy = metrics.accuracy_score(y_true=y_true, y_pred=m_vote)\n",
    "    return np.array(m_vote), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(\n",
    "    d_inner,\n",
    "    best_idxs,\n",
    "    use_idxs,\n",
    "    classifiers,\n",
    "    train_predictions_of_classifiers,\n",
    "    valid_predictions_of_classifiers,\n",
    "    test_predictions_of_classifiers,\n",
    "):\n",
    "    \"\"\"重み付けパラメーターdの更新と、最適化の結果使用しないとされた弱分類器の更新\"\"\"\n",
    "    # 重み付けパラメーターdを更新\n",
    "    for l in range(num_classes):\n",
    "        d_broadcast = np.broadcast_to(\n",
    "            d_inner[:, l], (len(best_idxs[l]), len(d_inner[:, l]))\n",
    "        ).copy()\n",
    "        tmp = (\n",
    "            y_train[l]\n",
    "            * np.sum(\n",
    "                d_broadcast * train_predictions_of_classifiers[best_idxs[l]][:, l, :],\n",
    "                axis=0,\n",
    "            )\n",
    "            - 1\n",
    "        ) ** 2\n",
    "        d_inner[:, l] *= tmp\n",
    "        if np.sum(d_inner[:, l]) == 0:\n",
    "            continue\n",
    "        d_inner[:, l] /= np.sum(d_inner[:, l])\n",
    "\n",
    "    # Update classifier dictionary\n",
    "    # 選択されていない分類器を、データに重み付けをした上で更新する\n",
    "    tmp = np.array(np.nonzero(use_idxs))\n",
    "    for c in range(tmp.shape[-1]):\n",
    "        i, l = tmp[:, c]\n",
    "        classifier = classifiers[l][i]\n",
    "        sample_indices = np.random.choice(np.arange(X_train.shape[0]), num_samples)\n",
    "        classifier.fit(\n",
    "            X=X_train[sample_indices],\n",
    "            y=y_train[i, sample_indices],\n",
    "            sample_weight=d_inner[sample_indices, i],\n",
    "        )\n",
    "        test_predictions_of_classifiers[l][i] = classifier.predict(X_test)\n",
    "        valid_predictions_of_classifiers[l][i] = classifier.predict(X_valid)\n",
    "\n",
    "    return (\n",
    "        d_inner,\n",
    "        classifiers,\n",
    "        valid_predictions_of_classifiers,\n",
    "        test_predictions_of_classifiers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_QUBO(Progress):\n",
    "    global timeout\n",
    "    global test_predictions_of_classifiers\n",
    "    global valid_predictions_of_classifiers\n",
    "    penalty = len(X_train) / num_classes / num_classifiers  # ペナルティ項の係数。今回は決め打ち\n",
    "    # Obtain predictions for train data　and prepare spins\n",
    "    spins, train_predictions_of_classifiers = preprocess(classifiers)\n",
    "    # Create QUBO formulation\n",
    "    f = createQUBO(spins, penalty, train_predictions_of_classifiers)\n",
    "    use_indices = solve(f, spins)\n",
    "    Progress.value += 1\n",
    "    return use_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_simpleQUBO(use_indices):\n",
    "    # バリデーションデータに対する正解率を計算\n",
    "    valid_pred, valid_acc, _ = compute_accuracy(\n",
    "        use_indices, valid_predictions_of_classifiers, y_valid\n",
    "    )\n",
    "    # テストデータに対する正解率を計算\n",
    "    test_pred, test_acc, _ = compute_accuracy(\n",
    "        use_indices, test_predictions_of_classifiers, y_test\n",
    "    )\n",
    "    for i in range(len(test_acc)):\n",
    "        print(f\"QBoost(step 1) class {i}: {test_acc[i]*100} %\")\n",
    "        results[\"QBoost(step 1)\"][f\"class {i}\"] = test_acc[i] * 100\n",
    "\n",
    "    if num_classes > 2:\n",
    "        m_vote, accuracy = model_output(test_pred, valid_acc, y_test_tmp)\n",
    "        print(f\"QBoost(step 1): {accuracy*100} %\")\n",
    "        results[\"QBoost(step 1)\"][\"Total\"] = accuracy * 100\n",
    "        results[\"QBoost(step 1)\"][\"num classifiers\"] = sum(\n",
    "            len(use_indices[i]) for i in range(num_classes)\n",
    "        )\n",
    "        plot_features(X_test, np.array(m_vote), title=\"QBoost(step 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qboost(Progress):\n",
    "    global classifiers\n",
    "    global test_predictions_of_classifiers\n",
    "    global valid_predictions_of_classifiers\n",
    "    penalty = len(X_train) / num_classes / num_classifiers\n",
    "\n",
    "    MAX_ITER = 1000\n",
    "    EPS = 1e-8\n",
    "\n",
    "    client = FixstarsClient()\n",
    "    client.parameters.timeout = 500\n",
    "    solver = Solver(client)\n",
    "\n",
    "    prev_acc = -1\n",
    "    best_acc = -1\n",
    "    best_idxs = None\n",
    "    best_T = -1\n",
    "    best_lam = None\n",
    "\n",
    "    # initialization\n",
    "    d_inner = np.full((len(X_train), num_classes), 1 / len(X_train))\n",
    "    T_inner = 0\n",
    "    lam = np.arange(0.001, penalty / 10, 0.01)\n",
    "    use_idxs = np.ones((num_classes, num_classifiers))\n",
    "    Progress.value += 1\n",
    "\n",
    "    # fix seed\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for _iter in range(MAX_ITER):\n",
    "        assert (\n",
    "            abs(np.sum(d_inner, axis=0) - 1) < EPS\n",
    "        ).all()  # 重み付け用のパラメーターがきちんとスケーリングされているかチェック\n",
    "        for penalty in lam:\n",
    "            print(\"iteration :\", _iter, \"lambda =\", penalty)\n",
    "            print(f\"Best : {best_acc*100}%\")\n",
    "            # 変数の用意・学習データに対する推論結果の計算\n",
    "            spins, train_predictions_of_classifiers = preprocess(classifiers)\n",
    "            # QUBOモデルの作成\n",
    "            f = createQUBO(spins, penalty, train_predictions_of_classifiers)\n",
    "            # 求解・解の取り出し\n",
    "            temporal_idxs = solve(f, spins)\n",
    "            # クラスラベルごとの正解率を計算\n",
    "            predictions_qboost, valid_acc, accept = compute_accuracy(\n",
    "                temporal_idxs, valid_predictions_of_classifiers, y_valid\n",
    "            )\n",
    "            if not accept:  # 最適化の結果、あるクラスの分類器を使わないことが最適とされた場合は処理を終了し次のループへ進む\n",
    "                continue\n",
    "            if num_classes > 2:  # 統合した結果を計算\n",
    "                m_vote, accuracy = model_output(\n",
    "                    predictions_qboost, valid_acc, y_valid_tmp\n",
    "                )\n",
    "\n",
    "            if (accuracy >= best_acc).all():  # 正解率が向上した場合、得られた解を最良解とする\n",
    "                best_acc = accuracy\n",
    "                best_idxs = temporal_idxs\n",
    "                best_T = sum(len(temporal_idxs[i]) for i in range(num_classes))\n",
    "                for i in range(num_classes):\n",
    "                    use_idxs[i, best_idxs[i]] = 0\n",
    "                    best_lam = penalty\n",
    "\n",
    "        if (prev_acc >= best_acc).all():  # 最良解の更新が止まったタイミングで処理を終了する\n",
    "            print(\n",
    "                \"Finish!\",\n",
    "                f\"Best acculacy = {best_acc*100}%, number of classifiers = {best_T}, best lambda = {best_lam}\",\n",
    "            )\n",
    "            break\n",
    "\n",
    "        prev_acc = best_acc\n",
    "\n",
    "        # 重みづけパラメーターと、未使用の分類器を更新\n",
    "        (\n",
    "            d_inner,\n",
    "            classifiers,\n",
    "            valid_predictions_of_classifiers,\n",
    "            test_predictions_of_classifiers,\n",
    "        ) = update_parameters(\n",
    "            d_inner,\n",
    "            best_idxs,\n",
    "            use_idxs,\n",
    "            classifiers,\n",
    "            train_predictions_of_classifiers,\n",
    "            valid_predictions_of_classifiers,\n",
    "            test_predictions_of_classifiers,\n",
    "        )\n",
    "        Progress.value += 1\n",
    "        Progress.value += 1\n",
    "        clear_output()\n",
    "    clear_output()\n",
    "    return best_idxs, best_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_qboost(best_idxs, best_T):\n",
    "    global test_predictions_of_classifiers\n",
    "    global valid_predictions_of_classifiers\n",
    "    valid_pred, valid_acc, _ = compute_accuracy(\n",
    "        best_idxs, valid_predictions_of_classifiers, y_valid\n",
    "    )\n",
    "    test_pred, test_acc, _ = compute_accuracy(\n",
    "        best_idxs, test_predictions_of_classifiers, y_test\n",
    "    )\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        print(f\"QBoost(step 2) class {i}: {test_acc[i]*100} %\")\n",
    "        results[\"QBoost(step 2)\"][f\"class {i}\"] = test_acc[i] * 100\n",
    "    print(f\"Total classifiers: {best_T}\")\n",
    "\n",
    "    if num_classes > 2:\n",
    "        m_vote, accuracy = model_output(test_pred, valid_acc, y_test_tmp)\n",
    "        print(f\"QBoost(step 2): {accuracy*100} %\")\n",
    "        results[\"QBoost(step 2)\"][\"Total\"] = accuracy * 100\n",
    "        results[\"QBoost(step 2)\"][\"num classifiers\"] = best_T\n",
    "        plot_features(X_test, np.array(m_vote), title=\"QBoost(step 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_slider = IntSlider(\n",
    "    value=80,\n",
    "    min=0,\n",
    "    max=300,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    ")\n",
    "time_slider = IntSlider(\n",
    "    value=1500,\n",
    "    min=100,\n",
    "    max=5000,\n",
    "    step=50,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    ")\n",
    "\n",
    "\n",
    "options1 = [Label(value=\"クラスごとの弱分類器の数:\"), classifier_slider]\n",
    "\n",
    "options2 = [Label(value=\"制限時間 [ ms ] :\"), time_slider]\n",
    "\n",
    "options = [GridBox(options1), GridBox(options2)]\n",
    "options = Accordion(children=[HBox(options)])\n",
    "options.set_title(0, \"Options\")\n",
    "options.selected_index = None\n",
    "\n",
    "Progress = IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=7,\n",
    "    step=1,\n",
    "    description=\"Solving...\",\n",
    "    bar_style=\"info\",\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "qboost_run_btn = Button(\n",
    "    description=\"Run(QBoost:step 2)\",\n",
    "    button_style=\"\",\n",
    "    tooltip=\"Run(QBoost:step 2)\",\n",
    "    icon=\"check\",\n",
    ")\n",
    "\n",
    "simpleQUBO_run_btn = Button(\n",
    "    description=\"Run(QBoost:step 1)\",\n",
    "    button_style=\"\",\n",
    "    tooltip=\"Run(QBoost:step 1)\",\n",
    "    icon=\"check\",\n",
    ")\n",
    "\n",
    "majority_run_btn = Button(\n",
    "    description=\"Run(Majority of vote)\",\n",
    "    button_style=\"\",\n",
    "    tooltip=\"Run(Majority of vote)\",\n",
    "    icon=\"check\",\n",
    ")\n",
    "\n",
    "\n",
    "Solve_out = Output()\n",
    "Problem_out = Output()\n",
    "\n",
    "\n",
    "def show_Iris_problem(num_classifiers, timeout, seed=0):\n",
    "    global Progress\n",
    "    Progress.value = 0\n",
    "    init(num_classifiers, timeout)\n",
    "    plot_features(X_test, y_test_tmp, title=\"Ground Truth\")\n",
    "\n",
    "\n",
    "def display_table():\n",
    "    with Problem_out:\n",
    "        Problem_out.clear_output()\n",
    "        df = pd.DataFrame(results)\n",
    "        display(\"Results\")\n",
    "        display(df.T)\n",
    "        plot_features(X_test, y_test_tmp, title=\"Ground Truth\")\n",
    "\n",
    "\n",
    "def show_Majority_result(btn):\n",
    "    global Progress\n",
    "    Progress.value = 0\n",
    "    with Solve_out:\n",
    "        Progress.value += 1\n",
    "        Solve_out.clear_output()\n",
    "        Progress.value += 1\n",
    "        display(\"Computation log\")\n",
    "        predict_majority(Progress)\n",
    "        Progress.value += 10\n",
    "        display_table()\n",
    "\n",
    "\n",
    "def show_Simple_result(btn):\n",
    "    global Progress\n",
    "    Progress.value = 0\n",
    "    with Solve_out:\n",
    "        Progress.value += 1\n",
    "        Solve_out.clear_output()\n",
    "        Progress.value += 1\n",
    "        display(\"Computation log\")\n",
    "        solution = simple_QUBO(Progress)\n",
    "        Progress.value += 1\n",
    "        predict_simpleQUBO(solution)\n",
    "        Progress.value += 10\n",
    "        display_table()\n",
    "\n",
    "\n",
    "def show_QBoost_result(btn):\n",
    "    global Progress\n",
    "    Progress.value = 0\n",
    "    with Solve_out:\n",
    "        Progress.value += 1\n",
    "        Solve_out.clear_output()\n",
    "        Progress.value += 1\n",
    "        display(\"Computation log\")\n",
    "        best_idxs, best_T = qboost(Progress)\n",
    "        Progress.value += 1\n",
    "        display(\"Computation log\")\n",
    "        predict_qboost(best_idxs, best_T)\n",
    "        Progress.value += 10\n",
    "        display_table()\n",
    "\n",
    "\n",
    "Problem_out = interactive_output(\n",
    "    show_Iris_problem,\n",
    "    {\n",
    "        \"num_classifiers\": classifier_slider,\n",
    "        \"timeout\": time_slider,\n",
    "    },\n",
    ")\n",
    "\n",
    "Solve_out = interactive_output(\n",
    "    show_Iris_problem,\n",
    "    {\n",
    "        \"num_classifiers\": classifier_slider,\n",
    "        \"timeout\": time_slider,\n",
    "    },\n",
    ")\n",
    "\n",
    "majority_run_btn.on_click(show_Majority_result)\n",
    "simpleQUBO_run_btn.on_click(show_Simple_result)\n",
    "qboost_run_btn.on_click(show_QBoost_result)\n",
    "\n",
    "grid = GridspecLayout(10, 12)\n",
    "right = 3\n",
    "\n",
    "grid[1:, :right] = Problem_out\n",
    "grid[0, 0] = majority_run_btn\n",
    "grid[0, 1] = simpleQUBO_run_btn\n",
    "grid[0, 2] = qboost_run_btn\n",
    "grid[0, 3] = Progress\n",
    "grid[1:, right:] = Solve_out\n",
    "\n",
    "\n",
    "display(VBox([options, grid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 }
}
